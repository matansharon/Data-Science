{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id='F:\\python\\Data_Science\\models\\medalpaca-13b.Q8_0.gguf', gpu_layers=30 )\n",
    "\n",
    "# print(llm(\"AI is going to\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nElcam Medical is a leading global provider of innovative, cost-effective medical device solutions. Since its establishment in 1983, the company has been dedicated to enabling high performance endovascular devices to perform faster, cleaner, less traumatically, at higher integrity and more easily with an excellent long term record for durability, consistency of clinical performance, quality, value and service.\\nThe Company is based in Israel where it operates its main R&D facility and manufacturing center as well as offices around the world including North America, Europe, Japan, Australia, South Korea, China and India. Elcam Medical’s products are marketed and distributed worldwide by sales organizations, direct subsidiaries or distributors.\\nElcam Medical is a privately held company with more than 35 years of successful medical technology product innovation history that has established it as the global leader in its field. The Company’s success is based on its ability to develop and manufacture high quality products at competitive prices that consistently exceed the customers' requirements for safety, performance and reliability.\\nElcam Medical’s highly qualified and experienced management team combines strong leadership skills with broad business expertise to achieve prof\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"are you know about Elcam Medical?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStopcock is a type of valve used to control the flow of liquids, gases or air in pipes. The term “stopcock” refers to both a physical valve and its handle. Stopcocks are commonly found on hot and cold water supply pipes to sinks and toilets, but can also be used to control the flow of gas and air into a room.\\nA stopcock is made up of three main parts:\\na spindle that turns the valve;\\na lever (usually coloured red); and\\nthe valve itself, which can either be turned off or left open.\\nThe handle is usually coloured red to make it easy to spot if there’s a problem with the stopcock.\\nHow do I use a stopcock?\\nIf you need to turn on the water, find and release (unclog) any sinks in your house. Once the pipes are clear, you can turn on the main stopcock at the top of the stairs or in the loft. If there’s no stopcock here, it will be located nearby inside your heating or boiler. It has its own coloured spindle. Make sure water runs through every'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('what is stopckock?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nE3D is a non-profit organization. Its members include European industry and service providers active in the field of defence and security.\\nE3D’s mission is to promote the development, production and export of defence equipment and services in Europe.\\nE3D's Vision\\nA vibrant and innovative European defence industry that contributes to the security of the continent by delivering the most advanced military technology for a wide range of applications.\\nThe E3D Mission can only be met when EU defense exporters succeed both on the national market as well as in export markets. The E3D Vision is based on the following pillars:\\nEU defence industry must be able to compete with other world-class industries, and offer solutions that meet or exceed those of their international competitors. To do so, they need to develop technologically advanced products at an acceptable price/quality ratio;\\nEU defence industry must have access to the latest technologies, and a wide range of subcontractors with complementary capabilities in order to produce innovative solutions;\\nEuropean governments must facilitate European defense industries' efforts by establishing procurement programmes that allow them to\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('what is E3D?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: huggingface_hub<0.17,>=0.16.4 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from tokenizers) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.6.3)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (23.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<0.17,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\matan.s\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'TheBloke/medalpaca-13B-GGUF'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'TheBloke/medalpaca-13B-GGUF' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mf:\\python\\Data_Science\\some tests\\model_testing.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/Data_Science/some%20tests/model_testing.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall --upgrade tokenizers\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/Data_Science/some%20tests/model_testing.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTheBloke/medalpaca-13B-GGUF\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python/Data_Science/some%20tests/model_testing.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(model_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/Data_Science/some%20tests/model_testing.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/Data_Science/some%20tests/model_testing.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Tokenize the input text\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan.s\\AppData\\Local\\anaconda3\\envs\\ai\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:711\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    709\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[39m=\u001b[39m TOKENIZER_MAPPING[\u001b[39mtype\u001b[39m(config)]\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m tokenizer_class_fast \u001b[39mand\u001b[39;00m (use_fast \u001b[39mor\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 711\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class_fast\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    712\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    713\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\matan.s\\AppData\\Local\\anaconda3\\envs\\ai\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1796\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1790\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   1791\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load following files from cache: \u001b[39m\u001b[39m{\u001b[39;00munresolved_files\u001b[39m}\u001b[39;00m\u001b[39m and cannot check if these \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1792\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1793\u001b[0m     )\n\u001b[0;32m   1795\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(full_file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m full_file_name \u001b[39min\u001b[39;00m resolved_vocab_files\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m-> 1796\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   1797\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load tokenizer for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1798\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1799\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1800\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining all relevant files for a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1801\u001b[0m     )\n\u001b[0;32m   1803\u001b[0m \u001b[39mfor\u001b[39;00m file_id, file_path \u001b[39min\u001b[39;00m vocab_files\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   1804\u001b[0m     \u001b[39mif\u001b[39;00m file_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load tokenizer for 'TheBloke/medalpaca-13B-GGUF'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'TheBloke/medalpaca-13B-GGUF' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "\n",
    "model_name = \"TheBloke/medalpaca-13B-GGUF\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the input text\n",
    "text = \"This is a positive sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get the model's predictions\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs.logits.argmax(dim=1)\n",
    "\n",
    "# Print the predicted sentiment label\n",
    "if predictions == 0:\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
