{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_name_or_path = \"gptq\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def response(_input):\n",
    "    prompt = _input\n",
    "    prompt_template=f'''<s>[INST] {_input} [/INST]\n",
    "    '''\n",
    "\n",
    "    print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "    input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "    output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "    return (tokenizer.decode(output[0]))\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        _input = input(\"You: \")\n",
    "        if _input == \"exit\":\n",
    "            break\n",
    "        print(\"Bot:\", response(_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "Bot: <s><s> [INST] hey [/INST]\n",
      "     Hello! How can I help you today? If you have any specific questions or topics you'd like to discuss, feel free to ask. Otherwise, I'm here to provide information and answer any questions you might have to the best of my ability. Is there something particular you'd like to know or talk about? Let me know and I'll do my best to assist you.\n",
      "\n",
      "     In the meantime, I can tell you that I'm an artificial intelligence designed to assist with a wide range of tasks, from answering questions and providing information, to helping with research and data analysis. I can also help generate ideas, write code, and much more. So if you have something specific in mind, just let me know and I'll see what I can do.\n",
      "\n",
      "     I'm also happy to chat about almost any topic, so if you just want to talk about something you're interested in, feel free to share. I'm here to help make your day easier and more productive!\n",
      "\n",
      "     Is there something specific you'd like to discuss or ask about? Let me know and I'll do my best to help.\n",
      "\n",
      "     Have a great day! :-)</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "Bot: <s><s> [INST] how you doing? [/INST]\n",
      "     I'm just a computer program, I don't have the ability to feel emotions or do physical activities like a living being. I exist to process information and provide responses based on the data I've been given or the programming I've been designed with. How can I help you today?</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "Bot: <s><s> [INST] what is qlora? [/INST]\n",
      "    QLora is not a widely known term or acronym in various fields such as technology, finance, or science. It could be a typo or an obscure term specific to a particular context. If you could provide more context or information about where you encountered this term, I'd be happy to help with any clarification I can. If it's a typo, it's possible that you meant another term, such as \"QL,\" which could refer to various things in different contexts, such as QuickLogic, a semiconductor company, or \"QL,\" the abbreviation for the programming language \"QUERY Language,\" which is used in some databases. Without further context, it's difficult to determine the exact meaning of \"QLora.\"</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "Bot: <s><s> [INST]  [/INST]\n",
      "     I. Introduction\n",
      "        A. Brief explanation of the purpose of the essay\n",
      "        B. Importance of the topic\n",
      "        C. Thesis statement\n",
      "\n",
      "    II. Background of the Topic\n",
      "        A. Origin and evolution of the concept of mental health\n",
      "        B. Statistics and facts about mental health issues\n",
      "        C. Significance of addressing mental health in the modern world\n",
      "\n",
      "    III. The Role of Society in Mental Health\n",
      "        A. Stigma and discrimination against people with mental health issues\n",
      "        B. The impact of societal expectations and pressures on mental health\n",
      "        C. The importance of creating a supportive and inclusive environment\n",
      "\n",
      "    IV. Personal Factors Affecting Mental Health\n",
      "        A. Biological factors such as genetics and brain chemistry\n",
      "        B. Psychological factors such as thoughts, emotions, and behaviors\n",
      "        C. Social factors such as relationships, work, and finance\n",
      "\n",
      "    V. Strategies for Promoting Mental Health\n",
      "        A. Self-care practices such as exercise, healthy eating, and sleep\n",
      "        B. Social connections and support networks\n",
      "        C. Professional help and treatment options\n",
      "\n",
      "    VI. Conclusion\n",
      "        A. Restate thesis statement\n",
      "        B. Summarize key points\n",
      "        C. Call to action for readers to take steps to promote mental health\n",
      "        D. Final thoughts on the importance of addressing mental health in our lives.</s>\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
