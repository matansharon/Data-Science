We've been starting to look at how to answer probability questions.

And at this point we want to make sure that we understand how to calculate probability for discrete

random variables.

Now, we want to distinguish here between discrete and continuous random variables.

So continuous random variables are variables representing data sets that we can think of as being continuous.

So think about, for instance, dimensions like length, width and height, or maybe even area or volume.

One common example is the height of people we would call the height of people a continuous random variable,

because in theory people can take on any height, at least maybe within a particular range.

So we might say that somebody measures five feet six inches tall and then another person measures five

feet seven inches tall.

But we also recognize that there are many people who have some height in between five, six and five

seven.

We might have somebody who measures exactly five, six and a half or somebody who measures exactly five,

six and a quarter.

And if we go even more granular in our measurement, in theory, we could measure an infinite number

of different heights between five, six and five seven.

The only thing that's holding us back here is how granular we can get with our measurement.

But the concept is that if we had the ability to measure with more and more and more accurate precision,

we could find many different heights and infinite number of heights between five, six and five seven.

And so we can define the height of people as a continuous random variable.

The same would be true for time in normal life.

We might only be interested in measuring time in terms of maybe seconds, minutes or hours.

But at the Olympics, when we're talking about athletes who race down to the 10th of a second or 100th

of a second or even thousandth of a second, as long as we could continue measuring at a more and more

granular level, we can continue to distinguish between lengths of time.

And so time would be considered a continuous random variable.

Contrast this with the idea of discrete random variables.

The key here we want to think about is things that are countable.

For instance, number of children in a family.

It's impossible for a family to have 2.7 children or 4.2 children.

That family is always going to have zero one, two, three, etc. Number of children.

The number of children in the family are countable.

Or we could think about something like flipping a coin.

So coin flips and the number of heads that we get in those coin flips is always going to be zero one,

two, three, etc. It's impossible if we flip a coin two times to get half of a head or one and a half

heads, we're always going to get zero one or two heads in two coin flips and there's no in between.

Even if we could get more granular with our measurement, it doesn't make sense to say that we get one

and one half heads on two coin flips.

There's only these discrete values and nothing in between those values.

So just think about discrete random variables as countable variables with no logical in between values.

Whereas with continuous random variables we have in theory an infinite number of in between values.

And as long as we can get specific enough in our measurements, we could continue finding more and more

in between values.

So with that in mind, what we want to do now is make sure we understand how to do probability calculations

when we have a discrete random variable.

So let's go back to this idea of the coin flip and let's say that we flip a coin one time.

There are only two possible outcomes.

When we flip the coin one time, we can either flip heads or we can flip tails.

If we think about that in terms of probability, we could build ourselves a little table here and we

could say that the discrete random variable modeling, the number of heads that we get when we flip

that coin is x.

So this variable X here models the number of heads we get when we flip a coin.

And if we flip the coin one time, there are only two possible outcomes.

One is we flip heads zero times, The other is we flip heads one time.

Since we're only flipping the coin one time, there's no way to flip heads twice or three times.

And obviously negative numbers don't apply here.

So only two outcomes.

We flip heads zero times or we flip heads one time and then we can think about the probability of each

of these outcomes for this discrete random variable X.

Well, we would indicate that as the probability of X.

And so this value here in our table is the probability that we flip heads zero times when we flip the

coin one time.

Well, the probability of flipping heads zero times when we flip a coin once is equivalent to the probability

of flipping tails on that coin flip.

So that probability is one half the probability that we flip heads once when we flip the.

One time is also, of course, one half.

So we have a little table here with our discrete random variable x and the probability that we find

this particular value of x.

Now, if we want to represent that in a probability distribution, here's what that looks like.

We could make a probability distribution here.

We'll have the values that X can take on along the horizontal axis and along the vertical axis.

We'll have the probability that that particular value of x occurs.

So here's what the distribution would look like.

For one coin flip.

It's this distribution Here we see along the horizontal axis that in one coin flip x, the number of

heads that we get when we flip a coin one time can only take on the values.

Zero or one with one coin flip is only possible to flip heads zero times or one time.

So these are the only values we have along our horizontal axis.

We've put our vertical axis in units of sixteenths so that we can expand on this graph as we add more

flips to our table here.

So if we think about each unit here along the vertical axis as being out of 16, then eight divided

by 16 is the same as one half.

So our probability right here is one half.

Our probability at four over 16 is one fourth, our probability at two over 16 is one eighth.

So since we know from our little probability distribution table here that the probability of flipping

zero heads is one half, we've indicated that here with this bar that extends up to eight over 16 or

one half.

And then same thing here, the probability of flipping heads one time is also one half.

So we have that represented with this bar here.

This is what probability looks like for a single coin flip with the discrete random variable x representing

the number of heads that we flip on that coin flip.

If we now add a second coin flip to this scenario, now we're going to say that we flip a coin two times.

Well, we have to now account for all of these possibilities.

Notice what we did here is that we started with our original single coin flip, and we said that on

our first coin flip, we're either going to get heads or tails.

Now, on our second coin flip, we could get heads after flipping heads on the first flip, or we could

get heads after flipping tails on the first flip.

But we can also have the scenario where we flipped heads and tails on the first flip, but then tails

on the second flip.

So what was two possible outcomes with one coin flip is now four possible outcomes with two coin flips.

And if we express that probability in a table, here's what the table looks like.

So again, we still have the same discrete random variable here where x is the number of times that

we flip heads.

Now that we're flipping the coin, two times we can flip heads zero times one time or two times.

And the probability that each of these outcomes occurs is given here by the probability of X.

We see that flipping heads zero times only occurs in this scenario here where we get tails tails.

So there's a one in four chance that we flip heads zero times The probability that we flip heads two

times occurs one out of four total possible outcomes.

And that's here in this first scenario where we flip heads and then heads again.

And there are two different ways that we could flip heads one time out of four possible outcomes.

That's when we flip tails, then heads or heads than tails.

So the probability of flipping heads one time is two matching outcomes out of four total equally likely

outcomes.

So we have here our probability distribution.

And if we graph that, here's what that looks like.

Now in our graph, we can flip heads zero one or two times.

We can see that the probability of flipping heads zero times is one fourth.

So we've sketched that in.

The probability of flipping heads two times is also one fourth.

So we sketch that in and the probability of flipping heads one time is two out of four or one half.

So we sketch that in here and now this is the probability distribution for the discrete random variable

x, where x is the number of heads that we flip when we flip a coin two times.

So we're starting to get an idea here.

Let's look quickly at what happens when we expand this to three coin flips and then four coin flips.

So if we expand to three coin flips, here's what our table looks like now.

We kept everything we had before.

We said that this was our first coin flip in white, in blue was our second coin flip, and now in red

we've attached an extra flip to those first two.

And we've said that on this third flip, we flip heads every single time.

But of course, we also have to account for the same set of the first two flips, but where on the third

flip we flip tails every time.

So now with three coin flips our.

Were possible outcomes expands to eight possible outcomes, which means that our probability distribution

table, if we're flipping the coin three times, we can flip heads 012 or three times.

There are four different possible outcomes here.

And if we just count up here, the number of times that each of those can occur.

For instance, here, the only time that we flip heads zero times, it's when we get tails, tails,

tails.

So out of these eight possible outcomes, only one of them is flipping heads zero times.

And so the probability there is one eighth same thing here.

The probability of flipping heads three times is when we get heads, heads, heads, no tails.

We see that here.

That's one out of all eight of these outcomes.

So the probability there is one eight.

So we build out this table and now if we sketch this distribution in our graph, we see that it looks

like this.

What we're hopefully noticing at this point is that the distribution is always higher in the middle

and lower around the edges.

For all three of these scenarios where we were flipping a coin one time, two times, three times,

the distribution has roughly the same shape every time.

And if we flip a coin four times, so we add to this, we had our first flip, second flip, third flip,

Now we add a fourth flip.

So for all these scenarios here, we say that the fourth flip comes up as heads, and then we duplicate

this whole set and say that the fourth flip this time comes up as tails every time.

So our eight possible outcomes has now doubled to 16 possible outcomes, and our little probability

distribution table looks like this.

When we flip a coin four times, we can get zero one, two, three or four heads if we just count out

of all 16 outcomes here, the number of times that we get zero heads one, two, three or four heads

out of the 16, we can fill out here the probability of this specific number of heads.

And if we sketch this distribution into our graph, it looks like this.

And now we're really starting to see this sort of triangular shape of the probability distribution of

this discrete random variable.

And of course, if we kept going, this distribution would get more and more and more fine, more and

more accurate, and we would see that the general shape of the distribution would look something like

this, and it would approximate this curve more and more accurately as we add additional coin flips

to our distribution.

Now, all of that to say with this idea of a discrete random variable and its probability distribution,

we want to recognize that discrete probability is just like any other probability in the sense that

the probability of the discrete random variable is always going to sum to one or 100%.

Remember earlier we said that probability was always defined between zero and one.

And we can see here that all of these probabilities, all of these right hand columns in each of our

four tables here for one coin flip, two coin flips, three coin flips and four coin flips, all of

these probabilities are between zero and one.

We have our smallest probability here at 116, all the way up to our highest probability of one half.

All those values are between zero and one, and each of these right hand columns sums to one one half

plus one half is one, which we could also call 100%.

We could call each of these one half values 50%.

So 50% plus 50% is 100%.

Same thing here, one fourth plus two fourths plus one fourth is one or 100%.

If we add up 25%, 50% and 25%.

And that's going to be true for all of these.

You'll see here that this adds up to eight over eight or one and that this adds up to 16 over 16 or

one.

So that concept still holds with discrete random variables.

What we want to be able to do now is talk about how to calculate the expected value of a discrete random

variable.

And we also want to be able to look at variance and standard deviation for a variable X like we've been

talking about.

So expected value or that long term average is like what we talked about before when we looked at experimental

versus expected probability and to calculate it here for a discrete random variable.

So let's take this scenario where we have just one coin flip.

When we have a discrete random variable, we have to take what's essentially a weighted average.

So we look at here these different countable outcomes.

X, we say that when we flip a coin one time, we can either flip heads zero times or one time, and

the probability that each of those things occurs is one half.

So we take the possible outcomes here zero and one and we.

Wait each of them by their probability, one half.

And when we do the math here, we get zero plus one half or one half.

And what this tells us then, is that when we flip a coin one time, the expected value for the number

of times that we flip heads is one half.

So it's almost saying that we can expect half heads on our one coin flip, which of course doesn't make

sense when we flip a coin one time, we know that we can only flip heads zero times or one time we can

never flip it half of a time.

But this is what the expected value is saying.

And of course, in a way that makes sense because if we're trying to represent the number of times we

should expect heads on one coin flip, even though we know the only outcomes are zero or one, it would

be wrong to say that our expectation on one coin flip is always zero heads, or that our expectation

on one coin flip is always one heads.

We can't really use either one of these values.

We have to go in the middle because as we already know, we've looked at it already when we talked about

probability.

And we also should just know this intuitively.

We should expect to flip heads about 50% of the time.

And so if we're flipping a coin only one time in this theoretical world here, we should expect half

of a heads on that one flip.

Let's look at what happens, though, when we flip a coin two times, three times, four times to our

expected value.

So when we flip a coin, twice are expected.

Value is this We have all of our different outcomes zero one or two heads, and we wait them with their

associated probabilities.

And so when we do the math here, the result is zero plus one half plus one half or one.

And this then should make a lot more sense to us because we're saying if we flip a coin two times,

we expect to flip heads one time.

That is our long term average.

That is our expected value for this discrete random variable.

And of course, that makes sense to us.

What happens, though, when we flip a coin three times, this time we can flip heads zero times once,

twice or three times.

We weight these values with their associated probabilities and we get zero plus three over eight plus

six over eight plus three over eight, and we get 12 over eight or three halves.

Three halves.

Or we could think about this as one and a half.

So what this is saying is that if we flip a coin three times, we should expect one and a half heads,

which of course in the context of the discrete random variable where we know it can only take on the

values zero one, two and three one and one half heads doesn't make sense.

But as a long term average, of course it does make sense because we know that flipping a coin, we

should always get 50% heads, 50% tails as long as we're taking a big enough sample, as long as we're

flipping the coin enough times to get a good long term average.

And so if we're flipping the coin three times, of course, we should expect one and one half heads.

And then the last one, hopefully you can already guess by now, when we flip the coin four times,

we see that we have all the possible outcomes zero one, two, three or four head flips and we weight

them with their associated probabilities and we get zero plus four over 16, plus 12 over 16 plus 12

or 16 plus four over 16, and we end up with 32 over 16 or just two.

And that makes sense because when we flip a coin four times, we should expect long term on average

heads to come up two times.

So in a way, all of this should make sense.

But the real unlock here shows up in these odd values where we're flipping a coin one time or we're

flipping a coin three times the even values or flipping a coin two times, four times, six times,

etc. Those make sense to us.

We get these nice whole round numbers where the expected value is one, two, etc. But what these odd

values show us is that we can get an expected value, which is in fact our mean.

We call this the mean of the discrete random variable x, this is mu sub x and it represents the mean

and in the case of a discrete random variable, it's the expected value.

But these odd values show us that the mean of a discrete random variable can turn out to be a value

that is in between the discrete values that the variable can actually take on.

So even though here this variable can only take on values of zero or one, we find a long term average

of one half, even though here with three coin flips, the discrete random variable can only take values

of zero one, two or three.

This expected value formula.

This idea shows us that we can still calculate a mean even for a discrete variable where that mean ends

up being a value in between the values that the variable can actually assume.

So even though here we can only find values of zero one, two or three, the mean is three halves.

The mean is one and one half.

Not any of these values at all.

So we understand now the idea of the probability that a discrete random variable takes on a particular

value.

We've seen what that looks like in terms of the distribution, the probability distribution of that

discrete random variable.

And we understand now how to find the expected value or the mean of that discrete random variable.

And that the mean may be a value that is between some of the values that the discrete random variable

can actually assume.

So now that we have this mean, this expected value, we want to just talk about the variance and standard

deviation of a discrete random variable.

And this is going to be our variance formula for a discrete random variable.

These x sub values are just the individual values of the discrete random variable.

In this case, with four coin flips, that's zero one, two, three and four.

And then you'll see here the probability of each of those values.

So this little probability distribution table gives us all the information we need to substitute for

x abi and the probability of x sub i and then mu.

Here is the expected value that we looked at earlier.

It's the mean.

And so you can see what we're doing is just finding the difference between the value of the discrete

random variable and the mean.

And then we're squaring that distance.

Squaring the distance is going to guarantee that we get a positive outcome here for this x sub I minus

mu quantity squared.

So this value is always going to be positive and then we're going to multiply that by the probability

over here P of X and we're going to do that for each one of the possible values of X, and then we're

just going to add them all together.

That will give us the variance of this particular discrete random variable.

So let's do that for the discrete random variable x here where x models the number of times we flip

heads when we flip a coin four times.

So if we substitute, our variance here will be our first value of x, which is zero.

So we'll say zero minus the mean.

We calculated the mean down here and we said that that was.

Two.

So we get zero minus two quantity squared times the probability of getting zero heads when we flip the

coin four times, which we know is one out of 16.

So we multiply this by one over 16 and then we keep going until we get to the bottom of our probability

distribution chart here with x equals four.

So here our next row where X is one, we flip heads one time we get one minus two quantity squared times

four over 16.

And then we add to that when X is two here, two minus two quantity squared times the probability,

they're six over 16.

And then we add to that three minus two quantity squared multiplied by four over 16.

And then the last row here plus four minus two quantity squared times one over 16.

And of course, we're doing this by hand just so we can see the math.

But all modern scientific calculators and computer programs will calculate a variance for you based

on this kind of probability distribution.

So in reality, we're not ever doing this math by hand, but we just want to see what's actually going

on behind the scenes so we understand what's happening.

So this is the manual calculation.

And when we actually do this here, we get negative two.

Quantity squared is four, four times one over 16 is four over 16, one minus two is a negative one,

quantity squared is positive one.

So plus four over 16 two minus two is zero.

So that whole term is going to drop away.

Three minus two is one squared is one times four over 16 is four over 16 and then four minus two is

two.

Quantity squared is four times one over 16 is four over 16.

We end up with four plus four plus four plus four is 16.

So we get 16 over 16 or one.

And so our variance for this particular discrete random variable, the number of heads we flip when

we flip a coin four times is one.

And as we already know, the standard deviation we can find by taking the square root of variance.

So the standard deviation of this discrete random variable x will be the square root of variance or

the square root of one or just one.

Of course, these numbers worked out really cleanly for this particular variable.

That won't always be the case.

But now, even though we started with a discrete random variable, we can say that this particular discrete

random variable x has an expected value.

Or a mean of two, that it has a variance of one in a standard deviation of one.

And now we can use all this information to answer probability questions about the discrete random variable,

like what is the probability that we get more than 3.25 heads when we flip a coin four times, or the

probability that we flip some number of heads between 1.5 heads and 2.7 heads.

And we're not bound by these discrete values.

We've sort of, with these calculations, transformed what would otherwise be a completely countable,

discrete variable into something where we can examine the values in between.