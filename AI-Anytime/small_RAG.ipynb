{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76569268e-02  6.34958595e-02  4.87131663e-02  7.93049484e-02\n",
      "   3.74480151e-02  2.65273103e-03  3.93748954e-02 -7.09838420e-03\n",
      "   5.93614578e-02  3.15370075e-02  6.00980110e-02 -5.29051572e-02\n",
      "   4.06067595e-02 -2.59308219e-02  2.98427958e-02  1.12688739e-03\n",
      "   7.35148787e-02 -5.03818542e-02 -1.22386679e-01  2.37027854e-02\n",
      "   2.97265742e-02  4.24768254e-02  2.56337989e-02  1.99515815e-03\n",
      "  -5.69191836e-02 -2.71599442e-02 -3.29035930e-02  6.60248697e-02\n",
      "   1.19007140e-01 -4.58791628e-02 -7.26214647e-02 -3.25841382e-02\n",
      "   5.23413569e-02  4.50552553e-02  8.25307053e-03  3.67024280e-02\n",
      "  -1.39414705e-02  6.53919429e-02 -2.64272261e-02  2.06371697e-04\n",
      "  -1.36643583e-02 -3.62810344e-02 -1.95043348e-02 -2.89738476e-02\n",
      "   3.94270569e-02 -8.84091258e-02  2.62428215e-03  1.36713954e-02\n",
      "   4.83062603e-02 -3.11565734e-02 -1.17329232e-01 -5.11690266e-02\n",
      "  -8.85287672e-02 -2.18963381e-02  1.42985675e-02  4.44168337e-02\n",
      "  -1.34815322e-02  7.43392855e-02  2.66382322e-02 -1.98762473e-02\n",
      "   1.79191213e-02 -1.06052132e-02 -9.04263183e-02  2.13269182e-02\n",
      "   1.41204879e-01 -6.47168653e-03 -1.40377565e-03 -1.53609570e-02\n",
      "  -8.73572007e-02  7.22173899e-02  2.01403089e-02  4.25587408e-02\n",
      "  -3.49013470e-02  3.19604704e-04 -8.02970678e-02 -3.27472314e-02\n",
      "   2.85268351e-02 -5.13657480e-02  1.09389201e-01  8.19327235e-02\n",
      "  -9.84040126e-02 -9.34095532e-02 -1.51291462e-02  4.51248139e-02\n",
      "   4.94172238e-02 -2.51868088e-02  1.57077741e-02 -1.29290670e-01\n",
      "   5.31887589e-03  4.02342714e-03 -2.34571677e-02 -6.72983080e-02\n",
      "   2.92280465e-02 -2.60845292e-02  1.30624818e-02 -3.11663002e-02\n",
      "  -4.82714027e-02 -5.58859892e-02 -3.87505852e-02  1.20010853e-01\n",
      "  -1.03924265e-02  4.89704609e-02  5.53537235e-02  4.49359156e-02\n",
      "  -4.00967849e-03 -1.02959722e-01 -2.92968620e-02 -5.83401695e-02\n",
      "   2.70472653e-02 -2.20168810e-02 -7.22241178e-02 -4.13869321e-02\n",
      "  -1.93298571e-02  2.73326226e-03  2.76980747e-04 -9.67589170e-02\n",
      "  -1.00574695e-01 -1.41922869e-02 -8.07891563e-02  4.53924984e-02\n",
      "   2.45041270e-02  5.97613864e-02 -7.38185495e-02  1.19842980e-02\n",
      "  -6.63403943e-02 -7.69044757e-02  3.85157615e-02 -5.59362146e-33\n",
      "   2.80013606e-02 -5.60784712e-02 -4.86601815e-02  2.15570591e-02\n",
      "   6.01980761e-02 -4.81403023e-02 -3.50246951e-02  1.93314087e-02\n",
      "  -1.75151546e-02 -3.89210358e-02 -3.81064182e-03 -1.70287751e-02\n",
      "   2.82099638e-02  1.28290290e-02  4.71601449e-02  6.21029772e-02\n",
      "  -6.43588752e-02  1.29285574e-01 -1.31231323e-02  5.23069985e-02\n",
      "  -3.73681076e-02  2.89094262e-02 -1.68981142e-02 -2.37329751e-02\n",
      "  -3.33492681e-02 -5.16762659e-02  1.55356461e-02  2.08803285e-02\n",
      "  -1.25372456e-02  4.59579304e-02  3.72720435e-02  2.80566476e-02\n",
      "  -5.90004623e-02 -1.16988095e-02  4.92182821e-02  4.70328555e-02\n",
      "   7.35487193e-02 -3.70529443e-02  3.98463756e-03  1.06412042e-02\n",
      "  -1.61542950e-04 -5.27166687e-02  2.75928341e-02 -3.92921343e-02\n",
      "   8.44717249e-02  4.86860797e-02 -4.85872338e-03  1.79948900e-02\n",
      "  -4.28569727e-02  1.23376083e-02  6.39961194e-03  4.04823609e-02\n",
      "   1.48887420e-02 -1.53941400e-02  7.62947500e-02  2.37043723e-02\n",
      "   4.45237570e-02  5.08195199e-02 -2.31256452e-03 -1.88737176e-02\n",
      "  -1.23335831e-02  4.66002822e-02 -5.63437454e-02  6.29926622e-02\n",
      "  -3.15534659e-02  3.24912407e-02  2.34672837e-02 -6.55438155e-02\n",
      "   2.01708432e-02  2.57081911e-02 -1.23868166e-02 -8.36502109e-03\n",
      "  -6.64378032e-02  9.43073109e-02 -3.57093103e-02 -3.42483260e-02\n",
      "  -6.66356971e-03 -8.01534485e-03 -3.09712440e-02  4.33012508e-02\n",
      "  -8.21399316e-03 -1.50795057e-01  3.07691824e-02  4.00719047e-02\n",
      "  -3.79293673e-02  1.93209760e-03  4.00530547e-02 -8.77075121e-02\n",
      "  -3.68491150e-02  8.57951678e-03 -3.19251195e-02 -1.25257680e-02\n",
      "   7.35540166e-02  1.34737056e-03  2.05918867e-02  2.71097870e-33\n",
      "  -5.18577546e-02  5.78360260e-02 -9.18985307e-02  3.94421592e-02\n",
      "   1.05576545e-01 -1.96912698e-02  6.18403107e-02 -7.63465539e-02\n",
      "   2.40880754e-02  9.40048546e-02 -1.16535477e-01  3.71197686e-02\n",
      "   5.22425622e-02 -3.95858148e-03  5.72214313e-02  5.32853231e-03\n",
      "   1.24016851e-01  1.39022451e-02 -1.10249696e-02  3.56053263e-02\n",
      "  -3.30755524e-02  8.16573948e-02 -1.52004026e-02  6.05585016e-02\n",
      "  -6.01397082e-02  3.26102711e-02 -3.48296687e-02 -1.69882756e-02\n",
      "  -9.74907354e-02 -2.71484703e-02  1.74713659e-03 -7.68981501e-02\n",
      "  -4.31858636e-02 -1.89984813e-02 -2.91661546e-02  5.77488132e-02\n",
      "   2.41820812e-02 -1.16902711e-02 -6.21435307e-02  2.84351278e-02\n",
      "  -2.37497487e-04 -2.51783282e-02  4.39639203e-03  8.12840238e-02\n",
      "   3.64184231e-02 -6.04005717e-02 -3.65517624e-02 -7.93748796e-02\n",
      "  -5.08528762e-03  6.69699162e-02 -1.17784359e-01  3.23744491e-02\n",
      "  -4.71252874e-02 -1.34460023e-02 -9.48444903e-02  8.24945606e-03\n",
      "  -1.06748864e-02 -6.81882054e-02  1.11822155e-03  2.48020664e-02\n",
      "  -6.35889024e-02  2.84493174e-02 -2.61302870e-02  8.58111531e-02\n",
      "   1.14682272e-01 -5.35345674e-02 -5.63588776e-02  4.26008627e-02\n",
      "   1.09453900e-02  2.09578462e-02  1.00131169e-01  3.26051228e-02\n",
      "  -1.84208736e-01 -3.93208377e-02 -6.91454932e-02 -6.38105273e-02\n",
      "  -6.56385794e-02 -6.41248655e-03 -4.79612686e-02 -7.68132880e-02\n",
      "   2.95384284e-02 -2.29949411e-02  4.17037010e-02 -2.50047632e-02\n",
      "  -4.54508839e-03 -4.17136513e-02 -1.32289762e-02 -6.38357848e-02\n",
      "  -2.46475521e-03 -1.37338284e-02  1.68976765e-02 -6.30398393e-02\n",
      "   8.98880884e-02  4.18170504e-02 -1.85687561e-02 -1.80442186e-08\n",
      "  -1.67998113e-02 -3.21577750e-02  6.30383641e-02 -4.13092263e-02\n",
      "   4.44819145e-02  2.02472718e-03  6.29593357e-02 -5.17368177e-03\n",
      "  -1.00444751e-02 -3.05640567e-02  3.52672040e-02  5.58581203e-02\n",
      "  -4.67125252e-02  3.45102586e-02  3.29578891e-02  4.30114344e-02\n",
      "   2.94362046e-02 -3.03164739e-02 -1.71107911e-02  7.37484396e-02\n",
      "  -5.47910407e-02  2.77515501e-02  6.20159740e-03  1.58800296e-02\n",
      "   3.42978984e-02 -5.15753357e-03  2.35080235e-02  7.53134415e-02\n",
      "   1.92843545e-02  3.36197540e-02  5.09103797e-02  1.52497098e-01\n",
      "   1.64208114e-02  2.70528775e-02  3.75162661e-02  2.18553804e-02\n",
      "   5.66333942e-02 -3.95747684e-02  7.12313056e-02 -5.41377477e-02\n",
      "   1.03770394e-03  2.11853832e-02 -3.56309079e-02  1.09016962e-01\n",
      "   2.76538823e-03  3.13997380e-02  1.38422404e-03 -3.45738344e-02\n",
      "  -4.59277704e-02  2.88083814e-02  7.16906367e-03  4.84685041e-02\n",
      "   2.61018537e-02 -9.44074243e-03  2.82169245e-02  3.48724574e-02\n",
      "   3.69099639e-02 -8.58947542e-03 -3.53205316e-02 -2.47856639e-02\n",
      "  -1.91921201e-02  3.80708352e-02  5.99653907e-02 -4.22287397e-02]\n",
      " [ 8.64386186e-02  1.02762692e-01  5.39453421e-03  2.04442907e-03\n",
      "  -9.96337179e-03  2.53855530e-02  4.92875353e-02 -3.06265932e-02\n",
      "   6.87255114e-02  1.01366024e-02  7.75397494e-02 -9.00807977e-02\n",
      "   6.10618852e-03 -5.69898449e-02  1.41715184e-02  2.80491840e-02\n",
      "  -8.68464410e-02  7.64399469e-02 -1.03491269e-01 -6.77438304e-02\n",
      "   6.99946880e-02  8.44250992e-02 -7.24914437e-03  1.04770698e-02\n",
      "   1.34020578e-02  6.77576959e-02 -9.42086875e-02 -3.71689759e-02\n",
      "   5.22617251e-02 -3.10853552e-02 -9.63406265e-02  1.57716684e-02\n",
      "   2.57866755e-02  7.85245001e-02  7.89949223e-02  1.91516150e-02\n",
      "   1.64356027e-02  3.10080242e-03  3.81311364e-02  2.37090718e-02\n",
      "   1.05389496e-02 -4.40644808e-02  4.41739149e-02 -2.58727819e-02\n",
      "   6.15378395e-02 -4.05427217e-02 -8.64140093e-02  3.19722258e-02\n",
      "  -8.90599797e-04 -2.44436599e-02 -9.19721350e-02  2.33939737e-02\n",
      "  -8.30292925e-02  4.41511124e-02 -2.49693003e-02  6.23020120e-02\n",
      "  -1.30351842e-03  7.51395226e-02  2.46384777e-02 -6.47244602e-02\n",
      "  -1.17727794e-01  3.83392461e-02 -9.11767110e-02  6.35446012e-02\n",
      "   7.62739107e-02 -8.80240798e-02  9.54558328e-03 -4.69718017e-02\n",
      "  -8.41740146e-02  3.88823897e-02 -1.14393570e-01  6.28860481e-03\n",
      "  -3.49362046e-02  2.39751209e-02 -3.31317820e-02 -1.57243311e-02\n",
      "  -3.78955975e-02 -8.81246664e-03  7.06119463e-02  3.28066312e-02\n",
      "   2.03671656e-03 -1.12279005e-01  6.79724757e-03  1.22765619e-02\n",
      "   3.35303470e-02 -1.36201028e-02 -2.25490239e-02 -2.25228630e-02\n",
      "  -2.03194749e-02  5.04297279e-02 -7.48652667e-02 -8.22821334e-02\n",
      "   7.65962452e-02  4.93392572e-02 -3.75553109e-02  1.44635104e-02\n",
      "  -5.72457314e-02 -1.79954097e-02  1.09697975e-01  1.19462803e-01\n",
      "   8.09245277e-04  6.17057607e-02  3.26322243e-02 -1.30780146e-01\n",
      "  -1.48636669e-01 -6.16232641e-02  4.33886163e-02  2.67129503e-02\n",
      "   1.39785577e-02 -3.94002125e-02 -2.52711121e-02  3.87745304e-03\n",
      "   3.58664654e-02 -6.15420863e-02  3.76660600e-02  2.67564878e-02\n",
      "  -3.82659100e-02 -3.54793407e-02 -2.39227656e-02  8.67977142e-02\n",
      "  -1.84063166e-02  7.71038681e-02  1.39856699e-03  7.00383708e-02\n",
      "  -4.77877781e-02 -7.89819881e-02  5.10814637e-02 -2.99868205e-33\n",
      "  -3.91646028e-02 -2.56207213e-03  1.65210441e-02  9.48937424e-03\n",
      "  -5.66219501e-02  6.57783747e-02 -4.77002710e-02  1.11661935e-02\n",
      "  -5.73558100e-02 -9.16253496e-03 -2.17521153e-02 -5.59532531e-02\n",
      "  -1.11422576e-02  9.32792798e-02  1.66765023e-02 -1.36724235e-02\n",
      "   4.34389040e-02  1.87237456e-03  7.29946978e-03  5.16332537e-02\n",
      "   4.80608642e-02  1.35341480e-01 -1.71738882e-02 -1.29698385e-02\n",
      "  -7.50109404e-02  2.61108130e-02  2.69801710e-02  7.83014519e-04\n",
      "  -4.87270020e-02  1.17842406e-02 -4.59580496e-02 -4.83214296e-02\n",
      "  -1.95672009e-02  1.93889365e-02  1.98807381e-02  1.67431980e-02\n",
      "   9.87801179e-02 -2.74087396e-02  2.34808065e-02  3.70229711e-03\n",
      "  -6.14514649e-02 -1.21231726e-03 -9.50469822e-03  9.25156754e-03\n",
      "   2.38443650e-02  8.61232281e-02  2.26790234e-02  5.45120623e-04\n",
      "   3.47129516e-02  6.25461061e-03 -6.92774262e-03  3.92400064e-02\n",
      "   1.15674585e-02  3.26280147e-02  6.22155853e-02  2.76114289e-02\n",
      "   1.86883826e-02  3.55805345e-02  4.11795415e-02  1.54782142e-02\n",
      "   4.22692187e-02  3.82248238e-02  1.00314012e-02 -2.83245761e-02\n",
      "   4.47052233e-02 -4.10459079e-02 -4.50546248e-03 -5.44734262e-02\n",
      "   2.62320898e-02  1.79862268e-02 -1.23118751e-01 -4.66952436e-02\n",
      "  -1.35913501e-02  6.46710545e-02  3.57344374e-03 -1.22234141e-02\n",
      "  -1.79382171e-02 -2.55502760e-02  2.37224102e-02  4.08666953e-03\n",
      "  -6.51475340e-02  4.43651937e-02  4.68595922e-02 -3.25174965e-02\n",
      "   4.02275147e-03 -3.97606660e-03  1.11939432e-02 -9.95597616e-02\n",
      "   3.33168022e-02  8.01060274e-02  9.42692310e-02 -6.38294369e-02\n",
      "   3.23152468e-02 -5.13553470e-02 -7.49873929e-03  5.30053362e-34\n",
      "  -4.13194448e-02  9.49647203e-02 -1.06401451e-01  4.96590361e-02\n",
      "  -3.41913663e-02 -3.16745602e-02 -1.71555988e-02  1.70099782e-03\n",
      "   5.79757616e-02 -1.21778343e-03 -1.68536101e-02 -5.16912825e-02\n",
      "   5.52999079e-02 -3.42647023e-02  3.08179110e-02 -3.10480818e-02\n",
      "   9.27532911e-02  3.72663438e-02 -2.37397570e-02  4.45893593e-02\n",
      "   1.46153392e-02  1.16239391e-01 -5.00112362e-02  3.88716757e-02\n",
      "   4.24751639e-03  2.56975982e-02  3.27243805e-02  4.29906845e-02\n",
      "  -1.36144441e-02  2.56122462e-02  1.06262304e-02 -8.46864507e-02\n",
      "  -9.52982008e-02  1.08400024e-01 -7.51600042e-02 -1.37774404e-02\n",
      "   6.37337863e-02 -4.49666800e-03 -3.25321630e-02  6.23613745e-02\n",
      "   3.48052718e-02 -3.54922079e-02 -2.00222898e-02  3.66607904e-02\n",
      "  -2.48836689e-02  1.01818806e-02 -7.01233447e-02 -4.31950912e-02\n",
      "   2.95332391e-02 -2.94901140e-04 -3.45386341e-02  1.46676125e-02\n",
      "  -9.83970463e-02 -4.70487885e-02 -8.85490514e-03 -8.89914259e-02\n",
      "   3.50995921e-02 -1.29601985e-01 -4.98865247e-02 -6.12047650e-02\n",
      "  -5.97797595e-02  9.46323201e-03  4.91217710e-02 -7.75026828e-02\n",
      "   8.09727237e-02 -4.79257554e-02  2.34377198e-03  7.57031068e-02\n",
      "  -2.40176041e-02 -1.52546111e-02  4.86738496e-02 -3.85968834e-02\n",
      "  -7.04831779e-02 -1.20347980e-02 -3.88790220e-02 -7.76016712e-02\n",
      "  -1.07243471e-02  1.04188547e-02 -2.13753786e-02 -9.17386264e-02\n",
      "  -1.11344634e-02 -2.96065565e-02  2.46458296e-02  4.65711206e-03\n",
      "  -1.63449869e-02 -3.95219885e-02  7.73373544e-02 -2.84732413e-02\n",
      "  -3.69940535e-03  8.27664956e-02 -1.10408571e-02  3.13983783e-02\n",
      "   5.35094850e-02  5.75145967e-02 -3.17622013e-02 -1.52911266e-08\n",
      "  -7.99661577e-02 -4.76796888e-02 -8.59789103e-02  5.69616407e-02\n",
      "  -4.08866331e-02  2.23832335e-02 -4.64444654e-03 -3.80131118e-02\n",
      "  -3.10670976e-02 -1.07278181e-02  1.97698642e-02  7.76997907e-03\n",
      "  -6.09474909e-03 -3.86376455e-02  2.80271936e-02  6.78137466e-02\n",
      "  -2.35351119e-02  3.21747400e-02  8.02540779e-03 -2.39106789e-02\n",
      "  -1.21997879e-03  3.14598978e-02 -5.24925627e-02 -8.06809310e-03\n",
      "   3.14774481e-03  5.11496589e-02 -4.44104858e-02  6.36013299e-02\n",
      "   3.85083668e-02  3.30432989e-02 -4.18728497e-03  4.95592505e-02\n",
      "  -5.69604859e-02 -6.49709674e-03 -2.49793380e-02 -1.60867255e-02\n",
      "   6.62289262e-02 -2.06310432e-02  1.08045794e-01  1.68547090e-02\n",
      "   1.43812457e-02 -1.32127134e-02 -1.29387408e-01  6.95215985e-02\n",
      "  -5.55773489e-02 -6.75413534e-02 -5.45820314e-03 -6.13593776e-03\n",
      "   3.90840992e-02 -6.28779531e-02  3.74063291e-02 -1.16570722e-02\n",
      "   1.29149891e-02 -5.52496240e-02  5.16076311e-02 -4.30842303e-03\n",
      "   5.80247678e-02  1.86945442e-02  2.27810629e-02  3.21666077e-02\n",
      "   5.37978895e-02  7.02849105e-02  7.49311745e-02 -8.41775537e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "0:\n",
      "www.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "1:\n",
      "SciPy and NumPy\n",
      "Eli Bressert\n",
      "Beijing • Cambridge • Farnham • K ¨oln • Sebastopol • Tokyo\n",
      "9781449305468_text.\n",
      "pdf   1 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "2:\n",
      "SciPy and NumPy\n",
      "by Eli Bressert\n",
      "Copyright © 2013 Eli Bressert.\n",
      " All rights reserved.\n",
      "\n",
      "Printed in the United States of America.\n",
      "\n",
      "Published by O’Reilly Media, Inc.\n",
      ", 1005 Gravenstein Highway North, Sebastopol, CA 95472.\n",
      "\n",
      "O’Reilly books may be purchased for educational, business, or sales promotional use.\n",
      " O nline\n",
      "editions are also available for most titles ( http://my.\n",
      "safariboo ksonline.\n",
      "com ).\n",
      " For more information,\n",
      "contact our corporate/institutional sales department: (800) 998-9938 or corporate@oreilly.\n",
      "com .\n",
      "\n",
      "Interior Designer: David Futato Project Manager: Paul C.\n",
      " Anagnostopoulos\n",
      "Cover Designer: Randy Comer Copyeditor: MaryEllen N.\n",
      " Oliver\n",
      "Editors: Rachel Roumeliotis, Proofreader: Richard Camp\n",
      "Meghan Blanchette Illustrators: E l iB r e s s e r t ,L a u r e lM u l l e r\n",
      "Production Editor: Holly Bauer\n",
      "November 2012: First edition\n",
      "Revision History for the First Edition:\n",
      "2012-10-3 1 First release\n",
      "Seehttp://oreilly.\n",
      "com/catalog/errata.\n",
      "csp?isbn=0636920020219 for release details.\n",
      "\n",
      "Nutshell Handbook, the Nutshell Handbook logo, and the O’Reilly logo are registered trademarks\n",
      "of O’Reilly Media, Inc.\n",
      " SciPy and NumPy , the image of a three-spined stickleback, and related trade\n",
      "dress are trademarks of O’Reilly Media, Inc.\n",
      "\n",
      "Many of the designations used by manufacturers and sellers to distinguish their products are\n",
      "claimed as trademarks.\n",
      " Where those designations appear in this book, and O’Reilly Media, Inc.\n",
      ",\n",
      "was aware of a trademark claim, the designations have been printed in caps or initial caps.\n",
      "\n",
      "While every precaution has been taken in the preparation of this book, the publisher and authors\n",
      "assume no responsibility for errors or omissions, or for damages resulting from the use of the\n",
      "information contained herein.\n",
      "\n",
      "ISBN: 978-1-449-30546-8\n",
      "[LSI]\n",
      "9781449305468_text.\n",
      "pdf   2 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "3:\n",
      "Table of Contents\n",
      "Preface .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "v\n",
      "1.\n",
      " Introduction .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "1\n",
      "1.\n",
      " 1 Why SciPy and NumPy? 1\n",
      "1.\n",
      "2 Getting NumPy and SciPy 2\n",
      "1.\n",
      "3 Working with SciPy and NumPy 3\n",
      "2.\n",
      " NumPy .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "5\n",
      "2.\n",
      " 1 NumPy Arrays 5\n",
      "2.\n",
      "2 Boolean Statements and NumPy Arrays 10\n",
      "2.\n",
      "3 Read and Write 12\n",
      "2.\n",
      "4 Math 1 4\n",
      "3 .\n",
      " S c i P y .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "1 7\n",
      "3.\n",
      " 1 Optimization and Minimization 1 7\n",
      "3.\n",
      "2 Interpolation 22\n",
      "3.\n",
      "3 Integration 26\n",
      "3.\n",
      "4 Statistics 28\n",
      "3.\n",
      "5 Spatial and Clustering Analysis 32\n",
      "3.\n",
      "6 Signal and Image Processing 38\n",
      "3.\n",
      "7 Sparse Matrices 40\n",
      "3.\n",
      "8 Reading and Writing Files Beyond NumPy 41\n",
      "4.\n",
      " SciKit: Taking SciPy One Step Further .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "4 3\n",
      "4.\n",
      " 1 Scikit-Image 43\n",
      "4.\n",
      "2 Scikit-Learn 48\n",
      "5.\n",
      " Conclusion .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "5 5\n",
      "5 .\n",
      " 1 Summary 55\n",
      "5.\n",
      "2 What’ s Next? 55\n",
      "iii\n",
      "9781449305468_text.\n",
      "pdf   3 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "4:\n",
      "9781449305468_text.\n",
      "pdf   4 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "5:\n",
      "Preface\n",
      "Python, a high-level language with easy-to-read syntax, is highly ﬂexible, which makes\n",
      "it an ideal language to learn and use.\n",
      " For science and R&D , a few extra packages are used\n",
      "to streamline the develop ment process and obtain goals with the fewest steps possible.\n",
      "\n",
      "Among the best of these are SciPy and NumPy .\n",
      " This book gives a brief overview of\n",
      "different tools in these two scientiﬁc packages, in order to jump start their use in the\n",
      "reader’s own research projects.\n",
      "\n",
      "NumPy and SciPy are the bread-and-butter Python extensions for numerical arrays\n",
      "and advanced data analysis.\n",
      " Hence, knowing what tools they contain and how to use\n",
      "them will make any programmer’ s life more enjoyable.\n",
      " This book will cover their uses,\n",
      "ranging from simple array creation to machine learning.\n",
      "\n",
      "Audience\n",
      "Anyone with basic (and upward) knowledge of Python is the targeted audience for this\n",
      "book.\n",
      " Although the tools in SciPy and NumPy are relatively advanced, using them is\n",
      "simple and should keep even a novice Python programmer happy .\n",
      "\n",
      "Contents of this Book\n",
      "This book covers the basics of SciPy and NumPy with some additional material.\n",
      "\n",
      "The ﬁrst chapter describes what the SciPy and NumPy packages are, and how to\n",
      "access and install them on your computer.\n",
      " Chapter 2 goes over the basics of NumPy ,\n",
      "starting with array creation.\n",
      " Chapter 3, which comprises the bulk of the book, covers\n",
      "a small sample of the voluminous SciPy toolbox.\n",
      " This chapter includes discussion and\n",
      "examples on integration, optimization, interpolation, and more.\n",
      " Chapter 4 discusses\n",
      "two well-known scikit packages: scikit-image and scikit-learn.\n",
      " These provide much\n",
      "more advanced material that can be immediately applied to real-world problems.\n",
      " In\n",
      "Chapter 5, the conclusion, we discuss what to do next for even more advanced material.\n",
      "\n",
      "v\n",
      "9781449305468_text.\n",
      "pdf   5 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "6:\n",
      "Conventions Used in This Book\n",
      "The following typographical conventions are used in this book:\n",
      "Plain text\n",
      "Indicates menu titles, menu options, menu buttons, and keyboard accelerators\n",
      "(such as Alt and Ctrl).\n",
      "\n",
      "Italic\n",
      "Indicates new terms, URLs, email addresses, ﬁlenames, ﬁle extensions, pathnames,\n",
      "directories, and Unix utilities.\n",
      "\n",
      "Constant width\n",
      "Indicates commands, options, switches, variables, attributes, keys, functions, types,\n",
      "classes, namespaces, methods, modules, properties, parameters, values, objects,\n",
      "events, event handlers, XML tags, HTML tags, macros, the contents of ﬁles, or\n",
      "the output from commands.\n",
      "\n",
      "This icon signiﬁes a tip, suggestion, or general note.\n",
      "\n",
      "This icon indicates a warning or caution.\n",
      "\n",
      "Using Code Examples\n",
      "This book is here to help you get your job done.\n",
      " In general, you may use the code in\n",
      "this book in your programs and documentation.\n",
      " Y ou do not need to contact us for\n",
      "permission unless you’re reproducing a signiﬁcant portion of the code.\n",
      " For example,\n",
      "writing a program that uses several chunks of code from this book does not require\n",
      "permission.\n",
      " Se lling or distributing a CD-ROM of examples from O’Reilly books does\n",
      "require permission.\n",
      " Answering a question by citing this book and quoting example\n",
      "code does not require permission.\n",
      " Incorporating a signiﬁcant amount of example code\n",
      "from this book into your product’ s documentation does require permission.\n",
      "\n",
      "We appreciate, but do not require, attribution.\n",
      " An attribution usually includes the title,\n",
      "author, publisher, and ISBN.\n",
      " For example: “ SciPy and NumPy by Eli Bressert (O’Reilly).\n",
      "\n",
      "Copyright 2013 Eli Bressert, 978-1-449-30546-8.\n",
      "”\n",
      "If you feel your use of code examples falls outside fair use or the permission given above,\n",
      "feel free to contact us at permissions@oreilly.\n",
      "com .\n",
      "\n",
      "We’d Like to Hear from You\n",
      "Please address comments and questions conce rning this book to the publisher:\n",
      "vi | Preface\n",
      "9781449305468_text.\n",
      "pdf   6 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "7:\n",
      "O’Reilly Media, Inc.\n",
      "\n",
      "1005 Gravenstein Highway North\n",
      "Sebastopol, CA 95472\n",
      "(800) 998-9938 (in the United States or Canada)\n",
      "(707) 829-05 15 (international or local)\n",
      "(707) 829-0104 (fax)\n",
      "We have a web page for this book, where we list errata, examples, links to the code and\n",
      "data sets used, and any additional information.\n",
      " Y ou can access this page at:\n",
      "http://oreil.\n",
      "ly/SciPy_NumPy\n",
      "T o comment or ask technical questions about this book, send email to:\n",
      "bookquestions@oreilly.\n",
      "com\n",
      "For more information about our books, courses, conferences, and news, see our website\n",
      "athttp://www.\n",
      "oreilly.\n",
      "com .\n",
      "\n",
      "Find us on Facebook: http://facebook.\n",
      "com/oreilly\n",
      "Follow us on Twitter: http://twitter.\n",
      "com/oreillym edia\n",
      "W a t c hu so nY o u T u b e : http://www.\n",
      "youtube.\n",
      "co m/oreillym edia\n",
      "Safari ®Books Online\n",
      "Safari Books O nline ( www.\n",
      "safariboo ksonline.\n",
      "com ) is an on-demand digital\n",
      "library that delivers expert content in both book and video form from the\n",
      "world’ s leading authors in technology and business.\n",
      "\n",
      "T echnology professionals, software developers, web designers, and business and cre-\n",
      "ative professionals use Safari Books O nline as their primary resource for research,\n",
      "problem solving, lea rning, and certiﬁcation training.\n",
      "\n",
      "Safari Books O nline offers a range of product mixes and pricing programs for o rgani-\n",
      "zations, government agencies, and individuals.\n",
      " Subscribers have access to thousands of\n",
      "books, tra ining videos, and prepublication manuscripts in one fully searchable data-\n",
      "base from publishers like O’Reilly Media, Prentice Hall Professional, Addison-Wesley\n",
      "Professional, Microsoft Press, Sams, Que, Peachpit Press, Focal Press, Cisco Press, John\n",
      "Wiley & Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT\n",
      "Press, Apress, Manning, New Riders, McGraw-Hill, Jones & Bart lett, Course T echnol-\n",
      "ogy , and dozens more.\n",
      " For more information about Safari Books O nline, please visit us\n",
      "online.\n",
      "\n",
      "Acknowledgments\n",
      "I would like to thank Meghan Blanchette and Julie Steele, my current and previous\n",
      "editors, for their patience, help, and expertise.\n",
      " This book wouldn’t have materialized\n",
      "without their assistance.\n",
      " The tips, warnings, and package tools discussed in the book\n",
      "Preface | vii\n",
      "9781449305468_text.\n",
      "pdf   7 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "8:\n",
      "were much improved thanks to the two book reviewers: T om Aldcroft and Sarah\n",
      "Kendrew .\n",
      " Colleagues and friends that have helped discuss certain aspects of this book\n",
      "and bolstered my drive to get it done are Leonardo T esti, Nate Bastian, Diederik\n",
      "Kruijssen, Joao Alves, Thomas Robitaille, and Farida Khatchadourian.\n",
      " A big thanks\n",
      "goes to my wife and son, Judith van Raalten and T aj Bressert, for their help and\n",
      "inspiration, and willi ngness to deal with me being huddled away behind the computer\n",
      "for endless hours.\n",
      "\n",
      "viii | Preface\n",
      "9781449305468_text.\n",
      "pdf   8 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "9:\n",
      "CHAPTER 1\n",
      "Introduction\n",
      "Python is a powerful programming language when considering portability , ﬂexibility ,\n",
      "syntax, style, and extendability .\n",
      " The language was written by Guido van Rossum\n",
      "with clean syntax built in.\n",
      " T o deﬁne a function or initiate a loop, indentation is used\n",
      "instead of brackets.\n",
      " The result is profound: a Python programmer can look at any given\n",
      "uncommented Python code and quickly understand its inner workings and purpose.\n",
      "\n",
      "Compiled languages like Fortran and C are natively much faster than Python, but not\n",
      "necessarily so when Python is bound to them.\n",
      " Using packages like Cython enables\n",
      "Python to interface with C code and pass information from the C program to Python\n",
      "and vice versa through memory .\n",
      " This allows Python to be on par with the faster\n",
      "languages when necessary and to use legacy code (e.\n",
      "g.\n",
      ", FFTW ).\n",
      " The combination of\n",
      "Python with fast computation has attracted scientists and others in large numbers.\n",
      "\n",
      "Two packages in particular are the powerhouses of scientiﬁc Python: NumPy and SciPy .\n",
      "\n",
      "Additionally , these two packages makes integrating legacy code easy .\n",
      "\n",
      "1.\n",
      "1 Why SciPy and NumPy?\n",
      "The basic operations used in scientiﬁc progra mming include arrays, matrices, integra-\n",
      "tion, differential equation solvers, statistics, and much more.\n",
      " Python, by default, does\n",
      "not have any of these functionalities built in, except for some basic mathematical op-\n",
      "erations that can only deal with a variable and not an array or matrix.\n",
      " NumPy and\n",
      "SciPy are two powerful Python packages, however, that enable the language to be used\n",
      "efﬁciently for scientiﬁc purposes.\n",
      "\n",
      "NumPy specializes in numerical processing through multi-dimensional ndarrays ,\n",
      "where the arrays allow element-by-element operations, a.\n",
      "k.\n",
      "a.\n",
      " broadcasting.\n",
      " If needed,\n",
      "linear algebra formalism can be used without modifying the NumPy arrays before-\n",
      "hand.\n",
      " Moreover, the arrays can be modiﬁed in size dynamically .\n",
      " This takes out the\n",
      "worries that usually mire quick programming in other languages.\n",
      " Rather than creating\n",
      "a new array when you want to get rid of certain elements, you can apply a mask to it.\n",
      "\n",
      "1\n",
      "9781449305468_text.\n",
      "pdf   9 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "10:\n",
      "SciPy is built on the NumPy array framework and takes scientiﬁc progra mming to\n",
      "a whole new level by supplying advanced mathematical functions like integration,\n",
      "ordinary differential equation solvers, special functions, optimizations, and more.\n",
      " T o\n",
      "list all the functions by name in SciPy would take several pages at minimum.\n",
      " When\n",
      "looking at the plethora of SciPy tools, it can sometimes be daunting even to decide\n",
      "which functions are best to use.\n",
      " That is why this book has been written.\n",
      " We will run\n",
      "through the primary and most often used tools, which will enable the reader to get\n",
      "results quickly and to explore the NumPy and SciPy packages with enough working\n",
      "knowledge to decide what is needed for problems that go beyond this book.\n",
      "\n",
      "1.\n",
      "2 Getting NumPy and SciPy\n",
      "Now you’re probably sold and asking, “Great, where can I get and install these pack-\n",
      "ages?” There are multiple ways to do this, and we will ﬁrst go over the easiest ways for\n",
      "OS X, Linux, and Windows.\n",
      "\n",
      "There are two well-known, comprehensive, precompiled Python packages that include\n",
      "NumPy and SciPy , and that work on all three platforms: the Enthought Python Dis-\n",
      "tribution (EPD) and ActivePython (AP).\n",
      " If you would like the free versions of the two\n",
      "packages, you should download EPD Free1or AP Community Edition.\n",
      "2If you need\n",
      "support, then you can always opt for the more compr ehensive packages from the two\n",
      "sources.\n",
      "\n",
      "Optionally , if you are a MacPorts3user, you can install NumPy and SciPy through the\n",
      "package manager.\n",
      " Use the MacPorts command as given below to install the Python\n",
      "packages.\n",
      " Note that installing SciPy and NumPy with MacPorts will take time, e spe-\n",
      "cially with the SciPy package, so it’ s a good idea to initiate the installation procedure\n",
      "and go grab a cup of tea.\n",
      "\n",
      "sudo port install py27-numpy py27-scipy py27-ipython\n",
      "MacPorts supports several versions of Python (e.\n",
      "g.\n",
      ", 2.\n",
      "6 and 2.\n",
      "7).\n",
      " So, although py27 is\n",
      "listed above, if you would like to use Python 2.\n",
      "6 instead with SciPy and NumPy then\n",
      "you would simply replace py27 with py26.\n",
      "\n",
      "If you’re using a Debian-based Linux distro like Ubuntu or Linux Mint, then use apt-get\n",
      "to install the packages.\n",
      "\n",
      "sudo apt-get install python-numpy python-scipy\n",
      "With an RPM-based system like Fedora or OpenSUSE, you can install the Python\n",
      "packages using yum.\n",
      "\n",
      "sudo yum install numpy scipy\n",
      "1http://www.\n",
      "enthought.\n",
      "com/products/epd_free.\n",
      "php\n",
      "2http://www.\n",
      "activestate.\n",
      "com/activepython/downloads\n",
      "3www.\n",
      "macports.\n",
      "com\n",
      "2 | Chapter 1: Introduction\n",
      "9781449305468_text.\n",
      "pdf   10 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "11:\n",
      "Building and installing NumPy and SciPy on Windows systems is more complicated\n",
      "than on the Unix-based systems, as code compilation is tricky .\n",
      " Fortunately , there is\n",
      "an excellent compiled binary installation program called python(x,y)4that has both\n",
      "NumPy and SciPy included and is Windows speciﬁc.\n",
      "\n",
      "For those who prefer building NumPy and SciPy from source, visit www.\n",
      "scipy.\n",
      "org/\n",
      "Download to download from either the stable or bleeding-edge repositories.\n",
      " Or clone\n",
      "the code repositories from scipy.\n",
      "github.\n",
      "com and numpy.\n",
      "github.\n",
      "com .\n",
      "U n l e s sy o u ’ r ea\n",
      "pro at building packages from source code and relish the challenge, though, I would\n",
      "recommend sticking with the precompiled package options as listed above.\n",
      "\n",
      "1.\n",
      "3 Working with SciPy and NumPy\n",
      "Y ou can work with Python programs in two different ways: interactively or through\n",
      "scripts.\n",
      " Some programmers swear that it is best to script all your code, so you don’t have\n",
      "to redo tedious tasks again when needed.\n",
      " Others say that interactive progra mming is\n",
      "the way to go, as you can explore the functionalities inside out.\n",
      " I would vouch for both,\n",
      "personally .\n",
      " If you have a terminal with the Python environment open and a text editor\n",
      "to write your script, you get the best of both worlds.\n",
      "\n",
      "For the interactive component, I highly recommend using IPython.\n",
      "5It takes the best of\n",
      "the bash environment (e.\n",
      "g.\n",
      ", using the tab button to complete a command and changing\n",
      "directories) and combines it with the Python environment.\n",
      " It does far more than this,\n",
      "but for the purpose of the examples in this book it should be enough to get it up and\n",
      "running.\n",
      "\n",
      "Bugs in programs are a fact of life and there’ s no way around them.\n",
      "\n",
      "Being able to ﬁnd bugs and ﬁx them quickly and easily is a big part\n",
      "of successful programming.\n",
      " IPython contains a feature where you can\n",
      "debug a buggy Python script by typing debug after running it.\n",
      " See http:/\n",
      "/ipython.\n",
      "org/ipython-doc/stable/interactive/tutorial.\n",
      "html for details under\n",
      "the debugging section.\n",
      "\n",
      "4http://code.\n",
      "google.\n",
      "com/p/pythonxy/\n",
      "5http://ipython.\n",
      "org/\n",
      "1.\n",
      "3 Working with SciPy and NumPy | 3\n",
      "9781449305468_text.\n",
      "pdf   11 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "12:\n",
      "9781449305468_text.\n",
      "pdf   12 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "13:\n",
      "CHAPTER 2\n",
      "NumPy\n",
      "2.\n",
      "1 NumPy Arrays\n",
      "NumPy is the fundamental Python package for scientiﬁc computing.\n",
      " It adds the capa-\n",
      "bilities of N-dimensional arrays, element-by-element operations (broadcasting), core\n",
      "mathematical operations like linear algebra, and the ability to wrap C/C ++/Fortran\n",
      "code.\n",
      " We will cover most of these aspects in this chapter by ﬁrst covering what NumPy\n",
      "arrays are, and their advantages versus Python lists and dictionaries.\n",
      "\n",
      "Python stores data in several different ways, but the most popular methods are lists\n",
      "anddictionaries .\n",
      " The Python list object can store nearly any type of Python object as\n",
      "an element.\n",
      " But operating on the elements in a list can only be done through iterative\n",
      "loops, which is computationally inefﬁcient in Python.\n",
      " The NumPy package enables\n",
      "users to overcome the shortcomings of the Python lists by providing a data storage\n",
      "object called ndarray .\n",
      "\n",
      "The ndarray is similar to lists, but rather than being highly ﬂexible by storing different\n",
      "types of objects in one list, only the same type of element can be stored in each column.\n",
      "\n",
      "For example, with a Python list, you could make the ﬁrst element a list and the second\n",
      "another list or dictionary .\n",
      " With NumPy arrays, you can only store the same type of\n",
      "element, e.\n",
      "g.\n",
      ", all elements must be ﬂoats, integers, or strings.\n",
      " Despite this limitation,\n",
      "ndarray wins hands down when it comes to operation times, as the operations are sped\n",
      "up signiﬁcantly .\n",
      " Using the %timeit magic command in IPython, we compare the power\n",
      "of NumPy ndarray versus Python lists in terms of speed.\n",
      "\n",
      "import numpy as np\n",
      "# Create an array with 10^7 elements.\n",
      "\n",
      "arr = np.\n",
      "arange(1e7)\n",
      "# Converting ndarray to list\n",
      "larr = arr.\n",
      "tolist()\n",
      "# Lists cannot by default broadcast,\n",
      "# so a function is coded to emulate\n",
      "# what an ndarray can do.\n",
      "\n",
      "5\n",
      "9781449305468_text.\n",
      "pdf   13 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "14:\n",
      "def list_times(alist, scalar):\n",
      "for i, val in enumerate(alist):\n",
      "alist[i] = val * scalar\n",
      "return alist\n",
      "# Using IPython's magic timeit command\n",
      "timeit arr * 1.\n",
      "1\n",
      ">>> 1 loops, best of 3: 76.\n",
      "9 ms per loop\n",
      "timeit list_times(larr, 1.\n",
      "1)\n",
      ">>> 1 loops, best of 3: 2.\n",
      "03 s per loop\n",
      "The ndarray operation is ∼25 faster than the Python loop in this example.\n",
      " Are you\n",
      "convinced that the NumPy ndarray is the way to go? From this point on, we will be\n",
      "working with the array objects instead of lists when possible.\n",
      "\n",
      "Should we need linear algebra operations, we can use the matrix object, which does not\n",
      "use the default broadcast operation from ndarray .\n",
      " For example, when you multiply two\n",
      "equally sized ndarrays , which we will denote as AandB,t h eni,jelement of Ais only\n",
      "multiplied by the ni,jelement of B.\n",
      " When multiplying two matrix objects, the usual\n",
      "matrix multiplication operation is executed.\n",
      "\n",
      "Unlike the ndarray objects, matrix objects can and only will be two dimensional.\n",
      " This\n",
      "means that trying to construct a third or higher dimension is not possible.\n",
      " Here’ s an\n",
      "example.\n",
      "\n",
      "import numpy as np\n",
      "# Creating a 3D numpy array\n",
      "arr = np.\n",
      "zeros((3,3,3))\n",
      "# Trying to convert array to a matrix, which will not work\n",
      "mat = np.\n",
      "matrix(arr)\n",
      "# \"ValueError: shape too large to be a matrix.\n",
      "\"\n",
      "If you are working with matrices, keep this in mind.\n",
      "\n",
      "2.\n",
      "1.\n",
      "1 Array Creation and Data Typing\n",
      "There are many ways to create an array in NumPy , and here we will discuss the ones\n",
      "that are most useful.\n",
      "\n",
      "# First we create a list and then\n",
      "# wrap it with the np.\n",
      "array() function.\n",
      "\n",
      "alist = [1, 2, 3]\n",
      "arr = np.\n",
      "array(alist)\n",
      "# Creating an array of zeros with five elements\n",
      "arr = np.\n",
      "zeros(5)\n",
      "# What if we want to create an array going from 0 to 100?\n",
      "arr = np.\n",
      "arange(100)\n",
      "6 | Chapter 2: NumPy\n",
      "9781449305468_text.\n",
      "pdf   14 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "15:\n",
      "# Or 10 to 100?\n",
      "arr = np.\n",
      "arange(10,100)\n",
      "# If you want 100 steps from 0 to 1.\n",
      ".\n",
      ".\n",
      "\n",
      "arr = np.\n",
      "linspace(0, 1, 100)\n",
      "# Or if you want to generate an array from 1 to 10\n",
      "# in log10 space in 100 steps.\n",
      ".\n",
      ".\n",
      "\n",
      "arr = np.\n",
      "logspace(0, 1, 100, base=10.\n",
      "0)\n",
      "# Creating a 5x5 array of zeros (an image)\n",
      "image = np.\n",
      "zeros((5,5))\n",
      "# Creating a 5x5x5 cube of 1's\n",
      "# The astype() method sets the array with integer elements.\n",
      "\n",
      "cube = np.\n",
      "zeros((5,5,5)).\n",
      "astype(int) + 1\n",
      "# Or even simpler with 16-bit floating-point precision.\n",
      ".\n",
      ".\n",
      "\n",
      "cube = np.\n",
      "ones((5, 5, 5)).\n",
      "astype(np.\n",
      "float16)\n",
      "When generating arrays, NumPy will default to the bit depth of the Python environ-\n",
      "ment.\n",
      " If you are working with 64-bit Python, then your elements in the arrays will\n",
      "default to 64-bit precision.\n",
      " This precision takes a fair chunk memory and is not al-\n",
      "ways necessary .\n",
      " Y ou can specify the bit depth when creating arrays by setting the data\n",
      "type parameter ( dtype )t o int,numpy.\n",
      "float16 ,numpy.\n",
      "float32 ,o r numpy.\n",
      "float64 .\n",
      "H e r e ’ s\n",
      "an example how to do it.\n",
      "\n",
      "# Array of zero integers\n",
      "arr = np.\n",
      "zeros(2, dtype=int)\n",
      "# Array of zero floats\n",
      "arr = np.\n",
      "zeros(2, dtype=np.\n",
      "float32)\n",
      "Now that we have created arrays, we can reshape them in many other ways.\n",
      " If we have\n",
      "a 25-element array , we can make it a 5 ×5 array , or we could make a 3-dimensional\n",
      "a r r a yf r o maﬂ a ta r r a y .\n",
      "\n",
      "# Creating an array with elements from 0 to 999\n",
      "arr1d = np.\n",
      "arange(1000)\n",
      "# Now reshaping the array to a 10x10x10 3D array\n",
      "arr3d = arr1d.\n",
      "reshape((10,10,10))\n",
      "# The reshape command can alternatively be called this way\n",
      "arr3d = np.\n",
      "reshape(arr1s, (10, 10, 10))\n",
      "# Inversely, we can flatten arrays\n",
      "arr4d = np.\n",
      "zeros((10, 10, 10, 10))\n",
      "arr1d = arr4d.\n",
      "ravel()\n",
      "print arr1d.\n",
      "shape\n",
      "(1000,)\n",
      "The possibilities for restructuring the arrays are large and, most importantly , easy .\n",
      "\n",
      "2.\n",
      "1 NumPy Arrays | 7\n",
      "9781449305468_text.\n",
      "pdf   15 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "16:\n",
      "Keep in mind that the restructured arrays above are just different views\n",
      "of the same data in memory .\n",
      " This means that if you modify one of the\n",
      "arrays, it will modify the others.\n",
      " For example, if you set the ﬁrst element\n",
      "ofarr1d from the example above to 1, then the ﬁrst element of arr3d will\n",
      "also become 1.\n",
      " If you don’t want this to happen, then use the numpy.\n",
      "copy\n",
      "function to separate the arrays memory-wise.\n",
      "\n",
      "2.\n",
      "1.\n",
      "2 Record Arrays\n",
      "Arrays are generally collections of integers or ﬂoats, but sometimes it is useful to store\n",
      "more complex data structures where columns are composed of different data types.\n",
      "\n",
      "In research journal publications, tables are commonly structured so that some col-\n",
      "umns may have string characters for identiﬁcation and ﬂoats for numerical quantities.\n",
      "\n",
      "Being able to store this type of information is very beneﬁcial.\n",
      " In NumPy there is the\n",
      "numpy.\n",
      "recarray .\n",
      " Constructing a recarray for the ﬁrst time can be a bit confusing, so we\n",
      "will go over the basics below .\n",
      " The ﬁrst example comes from the NumPy documentation\n",
      "on record arrays.\n",
      "\n",
      "# Creating an array of zeros and defining column types\n",
      "recarr = np.\n",
      "zeros((2,), dtype=('i4,f4,a10'))\n",
      "toadd = [(1,2.\n",
      ",'Hello'),(2,3.\n",
      ",\"World\")]\n",
      "recarr[:] = toadd\n",
      "The dtype optional argument is deﬁning the types designated for the ﬁrst to third\n",
      "columns, where i4corresponds to a 32-bit integer, f4corresponds to a 32-bit ﬂoat,\n",
      "and a10corresponds to a string 10 characters long.\n",
      " Details on how to deﬁne more\n",
      "types can be found in the NumPy documentation.\n",
      "1This example illustrates what the\n",
      "recarray looks like, but it is hard to see how we could populate such an array easily .\n",
      "\n",
      "Thankfully , in Python there is a global function called zipt h a tw i l lc r e a t eal i s to ft u p l e s\n",
      "like we see above for the toadd object.\n",
      " So we show how to use zipto populate the same\n",
      "recarray .\n",
      "\n",
      "# Creating an array of zeros and defining column types\n",
      "recarr = np.\n",
      "zeros((2,), dtype=('i4,f4,a10'))\n",
      "# Now creating the columns we want to put\n",
      "# in the recarray\n",
      "col1 = np.\n",
      "arange(2) + 1\n",
      "col2 = np.\n",
      "arange(2, dtype=np.\n",
      "float32)\n",
      "col3 = ['Hello', 'World']\n",
      "# Here we create a list of tuples that is\n",
      "# identical to the previous toadd list.\n",
      "\n",
      "toadd = zip(col1, col2, col3)\n",
      "# Assigning values to recarr\n",
      "recarr[:] = toadd\n",
      "1http://docs.\n",
      "scipy.\n",
      "org/doc/numpy/user/basics.\n",
      "rec.\n",
      "html\n",
      "8 | Chapter 2: NumPy\n",
      "9781449305468_text.\n",
      "pdf   16 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "17:\n",
      "# Assigning names to each column, which\n",
      "# are now by default called 'f0', 'f1', and 'f2'.\n",
      "\n",
      "recarr.\n",
      "dtype.\n",
      "names = ('Integers' , 'Floats', 'Strings')\n",
      "# If we want to access one of the columns by its name, we\n",
      "# can do the following.\n",
      "\n",
      "recarr('Integers')\n",
      "# array([1, 2], dtype=int32)\n",
      "The recarray structure may appear a bit tedious to work with, but this will become\n",
      "more important later on, when we cover how to read in complex data with NumPy in\n",
      "theRead and Write section.\n",
      "\n",
      "If you are doing research in astronomy or astrophysics and you commonly\n",
      "work with data tables, there is a high-level package called ATpy2that\n",
      "would be of interest.\n",
      " It allows the user to read, write, and convert data\n",
      "tables from/to FITS, ASCII, HDF5, and SQL formats.\n",
      "\n",
      "2.\n",
      "1.\n",
      "3 Indexing and Slicing\n",
      "Python index lists begin at zero and the NumPy arrays follow suit.\n",
      " When indexing lists\n",
      "in Python, we normally do the following for a 2 ×2 object:\n",
      "alist=[[1,2],[3,4]]\n",
      "# To return the (0,1) element we must index as shown below.\n",
      "\n",
      "alist[0][1]\n",
      "If we want to return the right-hand column, there is no trivial way to do so with Python\n",
      "lists.\n",
      " In NumPy , indexing follows a more convenient syntax.\n",
      "\n",
      "# Converting the list defined above into an array\n",
      "arr = np.\n",
      "array(alist)\n",
      "# To return the (0,1) element we use .\n",
      ".\n",
      ".\n",
      "\n",
      "arr[0,1]\n",
      "# Now to access the last column, we simply use .\n",
      ".\n",
      ".\n",
      "\n",
      "arr[:,1]\n",
      "# Accessing the columns is achieved in the same way,\n",
      "# which is the bottom row.\n",
      "\n",
      "arr[1,:]\n",
      "Sometimes there are more complex indexing schemes required, such as conditional\n",
      "indexing.\n",
      " The most commonly used type is numpy.\n",
      "where() .\n",
      "W i t ht h i sf u n c t i o ny o uc a n\n",
      "return the desired indices from an array , regardless of its dimensions, based on some\n",
      "conditions(s).\n",
      "\n",
      "2http://atpy.\n",
      "github.\n",
      "com\n",
      "2.\n",
      "1 NumPy Arrays | 9\n",
      "9781449305468_text.\n",
      "pdf   17 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "18:\n",
      "# Creating an array\n",
      "arr = np.\n",
      "arange(5)\n",
      "# Creating the index array\n",
      "index = np.\n",
      "where(arr > 2)\n",
      "print(index)\n",
      "(array([3, 4]),)\n",
      "# Creating the desired array\n",
      "new_arr = arr[index]\n",
      "However, you may want to remove speciﬁc indices instead.\n",
      " T o do this you can use\n",
      "numpy.\n",
      "delete() .\n",
      " The required input variables are the array and indices that you want\n",
      "to remove.\n",
      "\n",
      "# We use the previous array\n",
      "new_arr = np.\n",
      "delete(arr, index)\n",
      "Instead of using the numpy.\n",
      "where function, we can use a simple boolean array to return\n",
      "speciﬁc elements.\n",
      "\n",
      "index = arr > 2\n",
      "print(index)\n",
      "[False False True True True]\n",
      "new_arr = arr[index]\n",
      "Which method is better and when should we use one over the other? If speed is\n",
      "important, the boolean indexing is faster for a large number of elements.\n",
      " Additionally ,\n",
      "you can easily invert True and False objects in an array by using ∼index , a technique\n",
      "that is far faster than redoing the numpy.\n",
      "where function.\n",
      "\n",
      "2.\n",
      "2 Boolean Statements and NumPy Arrays\n",
      "Boolean statements are commonly used in combination with the andoperator and the\n",
      "oroperator.\n",
      " These operators are useful when comparing single boolean values to one\n",
      "another, but when using NumPy arrays, you can only use &and |as this allows fast\n",
      "comparisons of boolean values.\n",
      " Anyone fa miliar with formal logic will see that what we\n",
      "can do with NumPy is a natural extension to working with arrays.\n",
      " Below is an example\n",
      "of indexing using compound boolean statements, which are visualized in three subplots\n",
      "(see Figure 2-1) for context.\n",
      "\n",
      "Figure 2-1.\n",
      " Three plots showing how indexing with NumPy works.\n",
      "\n",
      "10 | Chapter 2: NumPy\n",
      "9781449305468_text.\n",
      "pdf   18 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "19:\n",
      "# Creating an image\n",
      "img1 = np.\n",
      "zeros((20, 20)) + 3\n",
      "img1[4:-4, 4:-4] = 6\n",
      "img1[7:-7, 7:-7] = 9\n",
      "# See Plot A\n",
      "# Let's filter out all values larger than 2 and less than 6.\n",
      "\n",
      "index1 = img1 > 2\n",
      "index2 = img1 < 6\n",
      "compound_index = index1 & index2\n",
      "# The compound statement can alternatively be written as\n",
      "compound_index = (img1 > 3) & (img1 < 7)\n",
      "img2 = np.\n",
      "copy(img1)\n",
      "img2[compound_index] = 0\n",
      "# See Plot B.\n",
      "\n",
      "# Making the boolean arrays even more complex\n",
      "index3 = img1 == 9\n",
      "index4 = (index1 & index2) | index3\n",
      "img3 = np.\n",
      "copy(img1)\n",
      "img3[index4] = 0\n",
      "# See Plot C.\n",
      "\n",
      "When constructing complex boolean arguments, it is important to use\n",
      "parentheses.\n",
      " Just as with the order of operations in math (PEMDAS), you\n",
      "need to organize the boolean arguments contained to construct the right\n",
      "logical statements.\n",
      "\n",
      "Alternatively , in a special case where you only want to operate on speciﬁc elements in\n",
      "an array , doing so is quite simple.\n",
      "\n",
      "import numpy as np\n",
      "import numpy.\n",
      "random as rand\n",
      "# Creating a 100-element array with random values\n",
      "# from a standard normal distribution or, in other\n",
      "# words, a Gaussian distribution.\n",
      "\n",
      "# The sigma is 1 and the mean is 0.\n",
      "\n",
      "a = rand.\n",
      "randn(100)\n",
      "# Here we generate an index for filtering\n",
      "# out undesired elements.\n",
      "\n",
      "inde x=a>0 .\n",
      " 2\n",
      "b = a[index]\n",
      "# We execute some operation on the desired elements.\n",
      "\n",
      "b=b* *2-2\n",
      "# Then we put the modified elements back into the\n",
      "# original array.\n",
      "\n",
      "a[index] = b\n",
      "2.\n",
      "2 Boolean Statements and NumPy Arrays | 11\n",
      "9781449305468_text.\n",
      "pdf   19 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "20:\n",
      "2.\n",
      "3 Read and Write\n",
      "Reading and writing information from data ﬁles, be it in text or binary format, is\n",
      "crucial for scientiﬁc computing.\n",
      " It provides the ability to save, share, and read data\n",
      "that is computed by any language.\n",
      " Fortunately , Python is quite capable of reading and\n",
      "writing data.\n",
      "\n",
      "2.\n",
      "3.\n",
      "1 Text Files\n",
      "In terms of text ﬁles, Python is one of the most capable progra mming languages.\n",
      " Not\n",
      "only is the parsing robust and ﬂexible, but it is also fast compared to other languages\n",
      "like C.\n",
      " Here’ s an example of how Python opens and parses text information.\n",
      "\n",
      "# Opening the text file with the 'r' option,\n",
      "# which only allows reading capability\n",
      "f = open('somefile.\n",
      "txt', 'r')\n",
      "# Parsing the file and splitting each line,\n",
      "# which creates a list where each element of\n",
      "# it is one line\n",
      "alist = f.\n",
      "readlines()\n",
      "# Closing file\n",
      "f.\n",
      "close()\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "# After a few operations, we open a new text file\n",
      "# to write the data with the 'w' option.\n",
      " If there\n",
      "# was data already existing in the file, it will be overwritten.\n",
      "\n",
      "f = open('newtextfile.\n",
      "txt', 'w')\n",
      "# Writing data to file\n",
      "f.\n",
      "writelines(newdata)\n",
      "# Closing file\n",
      "f.\n",
      "close()\n",
      "Accessing and recording data this way can be very ﬂexible and f ast, but there is one\n",
      "downside: if the ﬁle is large, then accessing or modulating the data will be cumbersome\n",
      "and slow .\n",
      " Getting the data directly into a numpy.\n",
      "ndarray would be the best option.\n",
      " We\n",
      "c a nd ot h i sb yu s i n gaN u m P yf u n c t i o nc a l l e d loadtxt .\n",
      " If the data is structured with\n",
      "rows and columns, then the loadtxt command will work very well as long as all the data\n",
      "is of a similar type, i.\n",
      "e.\n",
      ", integers or ﬂoats.\n",
      " W e can save the data through numpy.\n",
      "savetxt\n",
      "as easily and quickly as with numpy.\n",
      "readtxt .\n",
      "\n",
      "import numpy as np\n",
      "arr = np.\n",
      "loadtxt('somefile.\n",
      "txt')\n",
      "np.\n",
      "savetxt('somenewfile.\n",
      "txt')\n",
      "If each column is different in terms of formatting, loadtxt can still read the data, but\n",
      "the column types need to be predeﬁned.\n",
      " The ﬁnal construct from reading the data will\n",
      "12 | Chapter 2: NumPy\n",
      "9781449305468_text.\n",
      "pdf   20 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "21:\n",
      "be a recarray .\n",
      "H e r ew er u nt h r o u g has i m p l ee x a m p l et og e ta ni d e ao fh o wN u m P y\n",
      "deals with this more complex data structure.\n",
      "\n",
      "# example.\n",
      "txt file looks like the following\n",
      "#\n",
      "# XR21 32.\n",
      "789 1\n",
      "# XR22 33.\n",
      "091 2\n",
      "table = np.\n",
      "loadtxt('example.\n",
      "txt',\n",
      "dtype='names': ('ID', 'Result', 'Type'),\n",
      "'formats': ('S4', 'f4', 'i2'))\n",
      "# array([('XR21', 32.\n",
      "78900146484375, 1),\n",
      "# ('XR22', 33.\n",
      "090999603271484, 2)],\n",
      "# dtype=[('ID', '|S4'), ('Result', '<f4'), ('Type', '<i2')])\n",
      "Just as in the earlier material covering recarray objects, we can access each column by\n",
      "its name, e.\n",
      "g.\n",
      ", table[’Result’] .\n",
      " Accessing each row is done the same was as with normal\n",
      "numpy.\n",
      "array objects.\n",
      "\n",
      "There is one downside to recarray objects, though: as of version NumPy 1.\n",
      "8, there\n",
      "is no dependable and automated way to save numpy.\n",
      "recarray data structures in text\n",
      "f o r m a t .\n",
      "I fs a v i n g recarray structures is important, it is best to use the matplotlib.\n",
      "mlab3\n",
      "tools.\n",
      "\n",
      "There is a highly generalized and fast text parsing/writing package called\n",
      "Asciitable.\n",
      "4If reading and writing data in ASCII format is frequently\n",
      "needed for your work, this is a must-have package to use with NumPy .\n",
      "\n",
      "2.\n",
      "3.\n",
      "2 Binary Files\n",
      "T ext ﬁles are an excellent way to read, transfe r, and store data due to their built-in\n",
      "portability and user friendliness for viewing.\n",
      " Binary ﬁles in retrospect are harder to deal\n",
      "with, as formatting, readability , and portability are trickier.\n",
      " Y et they have two notable\n",
      "advantages over text-based ﬁles: ﬁle size and read/write speeds.\n",
      " This is especially\n",
      "important when working with big data.\n",
      "\n",
      "In NumPy , ﬁles can be accessed in binary format using numpy.\n",
      "save and numpy.\n",
      "load .\n",
      "\n",
      "The primary limitation is that the binary format is only read able to other systems that\n",
      "are using NumPy .\n",
      " If you want to read and write ﬁles in a more portable format, then\n",
      "scipy.\n",
      "io will do the job.\n",
      " This will be covered in the next chapter.\n",
      " For the time being,\n",
      "let us review NumPy’ s capabilities.\n",
      "\n",
      "import numpy as np\n",
      "# Creating a large array\n",
      "data = np.\n",
      "empty((1000, 1000))\n",
      "3http://matplotlib.\n",
      "sourceforge.\n",
      "net/api/mlab_api.\n",
      "html\n",
      "4http://cxc.\n",
      "harvard.\n",
      "edu/contrib/asciitable/\n",
      "2.\n",
      "3 Read and Write | 13\n",
      "9781449305468_text.\n",
      "pdf   21 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "22:\n",
      "# Saving the array with numpy.\n",
      "save\n",
      "np.\n",
      "save('test.\n",
      "npy', data)\n",
      "# If space is an issue for large files, then\n",
      "# use numpy.\n",
      "savez instead.\n",
      " It is slower than\n",
      "# numpy.\n",
      "save because it compresses the binary\n",
      "# file.\n",
      "\n",
      "np.\n",
      "savez('test.\n",
      "npz', data)\n",
      "# Loading the data array\n",
      "newdata = np.\n",
      "load('test.\n",
      "npy')\n",
      "Fortunately , numpy.\n",
      "save and numpy.\n",
      "savez have no issues saving numpy.\n",
      "recarray objects.\n",
      "\n",
      "Hence, working with complex and structured arrays is no issue if portability beyond\n",
      "the Python environment is not of concern.\n",
      "\n",
      "2.\n",
      "4 Math\n",
      "Python comes with its own math module that works on Python native objects.\n",
      " Unfor-\n",
      "tunately , if you try to use math.\n",
      "cos on a NumPy array , it will not work, as the math\n",
      "functions are meant to operate on elements and not on lists or arrays.\n",
      " Hence, NumPy\n",
      "comes with its own set of math tools.\n",
      " These are optimized to work with NumPy array\n",
      "objects and operate at fast speeds.\n",
      " When importing NumPy , most of the math tools are\n",
      "automatically included, from simple trigonometric and logarithmic functions to the\n",
      "more complex, such as fast Fourier transform (FFT) and linear algebraic operations.\n",
      "\n",
      "2.\n",
      "4.\n",
      "1 Linear Algebra\n",
      "NumPy arrays do not behave like matrices i n linear algebra by def ault.\n",
      " Inst ead, the\n",
      "operations are mapped from each element in one array onto the next.\n",
      " This is quite\n",
      "a useful feature, as loop operations can be done away with for efﬁciency .\n",
      " But what\n",
      "about when transposing or a dot multiplication are needed? Without invoking other\n",
      "classes, you can use the built-in numpy.\n",
      "dot and numpy.\n",
      "transpose to do such operations.\n",
      "\n",
      "The syntax is Pythonic, so it is intuitive to program.\n",
      " Or the math purist can use\n",
      "the numpy.\n",
      "matrix object instead.\n",
      " We will go over both examples below to illustrate\n",
      "the differences and similarities between the two opt ions.\n",
      " More importantly , we will\n",
      "compare some of the advantages and disadvantages between the numpy.\n",
      "array and the\n",
      "numpy.\n",
      "matrix objects.\n",
      "\n",
      "Some operations are easy and quick to do in linear algebra.\n",
      " A classic example is solving\n",
      "a system of equations that we can express in matrix form:\n",
      "3x+6y−5z=12\n",
      "x−3y+2z=−2\n",
      "5x−y+4z=10(2.\n",
      " 1)\n",
      "⎡\n",
      "⎣36 −5\n",
      "1−32\n",
      "5−14⎤\n",
      "⎦⎡\n",
      "⎣x\n",
      "y\n",
      "z⎤\n",
      "⎦=⎡\n",
      "⎣12\n",
      "−2\n",
      "10⎤\n",
      "⎦ (2.\n",
      "2)\n",
      "14 | Chapter 2: NumPy\n",
      "9781449305468_text.\n",
      "pdf   22 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "23:\n",
      "Now let us represent the matrix system as AX=B, and solve for the variables.\n",
      " This\n",
      "means we should try to obtain X=A−1B.\n",
      "H e r ei sh o ww ew o u l dd ot h i sw i t hN u m P y .\n",
      "\n",
      "import numpy as np\n",
      "# Defining the matrices\n",
      "A = np.\n",
      "matrix([[3, 6, -5],\n",
      "[1, -3, 2],\n",
      "[5, -1, 4]])\n",
      "B = np.\n",
      "matrix([[12],\n",
      "[-2],\n",
      "[10]])\n",
      "# Solving for the variables, where we invert A\n",
      "X=A* * (-1) * B\n",
      "print(X)\n",
      "# matrix([[ 1.\n",
      "75],\n",
      "# [ 1.\n",
      "75],\n",
      "# [ 0.\n",
      "75]])\n",
      "The solutions for the variables are x=1.\n",
      "75,y=1.\n",
      "75, and z=0.\n",
      "75.\n",
      " Y ou can easily check\n",
      "this by executing AX, which should produce the same elements deﬁned in B.\n",
      " Doing\n",
      "this sort of operation with NumPy is easy , as such a system can be expanded to much\n",
      "larger 2D matrices.\n",
      "\n",
      "Not all matrices are invertible, so this method of solving for solutions\n",
      "in a system does not always work.\n",
      " Y ou can sidestep this problem by\n",
      "using numpy.\n",
      "linalg.\n",
      "svd ,5which usually works well inverting poorly\n",
      "conditioned matrices.\n",
      "\n",
      "Now that we understand how NumPy matrices work, we can show how to do the same\n",
      "operations without speciﬁcally using the numpy.\n",
      "matrix subclass.\n",
      " (The numpy.\n",
      "matrix\n",
      "subclass is contained within the numpy.\n",
      "array class, which means that we can do the\n",
      "same example as that above without directly invoking the numpy.\n",
      "matrix class.\n",
      ")\n",
      "import numpy as np\n",
      "a = np.\n",
      "array([[3, 6, -5],\n",
      "[1, -3, 2],\n",
      "[5, -1, 4]])\n",
      "# Defining the array\n",
      "b = np.\n",
      "array([12, -2, 10])\n",
      "# Solving for the variables, where we invert A\n",
      "x = np.\n",
      "linalg.\n",
      "inv(a).\n",
      "dot(b)\n",
      "print(x)\n",
      "# array([ 1.\n",
      "75, 1.\n",
      "75, 0.\n",
      "75])\n",
      "5http://docs.\n",
      "scipy.\n",
      "org/doc/numpy/reference/generated/numpy.\n",
      "linalg.\n",
      "svd.\n",
      "html\n",
      "2.\n",
      "4 Math | 15\n",
      "9781449305468_text.\n",
      "pdf   23 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "24:\n",
      "Both methods of approaching linear algebra operations are viable, but which one is the\n",
      "best? The numpy.\n",
      "matrix method is syntactically the simplest.\n",
      " However, numpy.\n",
      "array is\n",
      "the most practical.\n",
      " First, the NumPy array is the standard for using nearly anything in\n",
      "the scientiﬁc Python environment, so bugs perta ining to the linear algebra operat ions\n",
      "will be less frequent than with numpy.\n",
      "matrix operations.\n",
      " Furthermore, in examples such\n",
      "as the two shown above, the numpy.\n",
      "array method is computationally faster.\n",
      "\n",
      "Passing data structures from one class to another can become cumbersome and lead\n",
      "to unexpected results when not done correctly .\n",
      " This would likely happen if one were to\n",
      "use numpy.\n",
      "matrix and then pass it to numpy.\n",
      "array for further operations.\n",
      " Sticking with\n",
      "one data structure will lead to fewer headaches and less worry than switching between\n",
      "matrices and arrays.\n",
      " It is advisable, then, to use numpy.\n",
      "array whenever possible.\n",
      "\n",
      "16 | Chapter 2: NumPy\n",
      "9781449305468_text.\n",
      "pdf   24 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "25:\n",
      "CHAPTER 3\n",
      "SciPy\n",
      "With NumPy we can achieve fast solutions with simple coding.\n",
      " Where does SciPy\n",
      "come into the picture? It’ s a package that utilizes NumPy arrays and manipulations to\n",
      "take on standard problems that scientists and engineers commonly face: integration,\n",
      "determining a function ’ s maxima or minima, ﬁnding eigenvectors for large sparse\n",
      "matrices, testing whether two distributions are the same, and much more.\n",
      " We will cover\n",
      "just the basics here, which will allow you to take advantage of the more complex features\n",
      "in SciPy by going through easy examples that are applicable to real-world problems.\n",
      "\n",
      "We will start with optimization and data ﬁtting, as these are some of the most common\n",
      "tasks, and then move through interpolation, integration, spatial analysis, clustering,\n",
      "signal and image processing, sparse matrices, and statistics.\n",
      "\n",
      "3.\n",
      "1 Optimization and Minimization\n",
      "The optimization package in SciPy allows us to solve minimization pr oblems easily and\n",
      "quickly .\n",
      " But wait: what is minimization and how can it help you with your work? Some\n",
      "classic examples are perfo rming linear regre ssion, ﬁnding a function’ s minimum and\n",
      "maximum values, determining the root of a function, and ﬁnding where two funct ions\n",
      "intersect.\n",
      " Below we begin with a simple linear regression and then expand it to ﬁtting\n",
      "non-linear data.\n",
      "\n",
      "The optimization and minimization tools that NumPy and SciPy pro vide\n",
      "are great, but they do not have Markov Chain Monte Carlo (MCMC)\n",
      "capabilities—in other words, Bayesian analysis.\n",
      " There are several popular\n",
      "MCMC Python packages like PyMC,1a rich package with many options,\n",
      "and emcee,2an afﬁne invariant MCMC ensemble sampler (meaning that\n",
      "large scales are not a problem for it).\n",
      "\n",
      "1http://pymc-devs.\n",
      "github.\n",
      "com/pymc/\n",
      "2http://danfm.\n",
      "ca/emcee/\n",
      "17\n",
      "9781449305468_text.\n",
      "pdf   25 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "26:\n",
      "3.\n",
      "1.\n",
      "1 Data Modeling and Fitting\n",
      "There are several ways to ﬁt data with a linear regression.\n",
      " In this section we will use\n",
      "curve_fit ,w h i c hi sa χ2-based method (in other words, a best-ﬁt method).\n",
      " In the\n",
      "example below , we generate data from a known function with noise, and then ﬁt the\n",
      "noisy data with curve_fit .\n",
      " The function we will model in the example is a simple linear\n",
      "equation, f( x)=ax+b.\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "optimize import curve_fit\n",
      "# Creating a function to model and create data\n",
      "def func(x, a, b):\n",
      "retur na*x+b\n",
      "# Generating clean data\n",
      "x = np.\n",
      "linspace(0, 10, 100)\n",
      "y = func(x, 1, 2)\n",
      "# Adding noise to the data\n",
      "y n=y+0 .\n",
      " 9* np.\n",
      "random.\n",
      "normal(size=len(x))\n",
      "# Executing curve_fit on noisy data\n",
      "popt, pcov = curve_fit(func, x, yn)\n",
      "# popt returns the best fit values for parameters of\n",
      "# the given model (func).\n",
      "\n",
      "print(popt)\n",
      "The values from popt, if a good ﬁt, should be close to the values for the yassignment.\n",
      "\n",
      "Y ou can check the quality of the ﬁt with pcov, where the diagonal elements are the\n",
      "variances for each parameter.\n",
      " Figure 3-1 gives a visual illustration of the ﬁt.\n",
      "\n",
      "T aking this a step further, we can do a least-squares ﬁt to a Gaussian proﬁle, a non-linear\n",
      "function:\n",
      "a∗exp/parenleftbigg−(x−μ)2\n",
      "2σ2/parenrightbigg\n",
      ",\n",
      "where ai sas c a l a r , μis the mean, and σis the standard deviation.\n",
      "\n",
      "# Creating a function to model and create data\n",
      "def func(x, a, b, c):\n",
      "return a*np.\n",
      "exp(-(x-b)**2/(2*c**2))\n",
      "# Generating clean data\n",
      "x = np.\n",
      "linspace(0, 10, 100)\n",
      "y = func(x, 1, 5, 2)\n",
      "# Adding noise to the data\n",
      "y n=y+0 .\n",
      " 2* np.\n",
      "random.\n",
      "normal(size=len(x))\n",
      "# Executing curve_fit on noisy data\n",
      "popt, pcov = curve_fit(func, x, yn)\n",
      "18 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   26 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "27:\n",
      "Figure 3-1.\n",
      " Fitting noisy data with a linear equation.\n",
      "\n",
      "Figure 3-2.\n",
      " Fitting noisy data with a Gaussian equation.\n",
      "\n",
      "# popt returns the best-fit values for parameters of the given model (func).\n",
      "\n",
      "print(popt)\n",
      "As we can see in Figure 3-2, the result from the Gaussian ﬁt is acceptable.\n",
      "\n",
      "Going one more step, we can ﬁt a one-dimensional dataset with multiple Gaussian\n",
      "proﬁles.\n",
      " The func is now expanded to include two Gaussian equations with different\n",
      "input variables.\n",
      " This example would be the classic case of ﬁtting line spectra (see\n",
      "Figure 3-3).\n",
      "\n",
      "3.\n",
      "1 Optimization and Minimization | 19\n",
      "9781449305468_text.\n",
      "pdf   27 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "28:\n",
      "Figure 3-3.\n",
      " Fitting noisy data with multiple Gaussian equations.\n",
      "\n",
      "# Two-Gaussian model\n",
      "def func(x, a0, b0, c0, a1, b1,c1):\n",
      "return a0*np.\n",
      "exp(-(x - b0) ** 2/(2 * c0 ** 2))\\\n",
      "+ a1 * np.\n",
      "exp(-(x - b1) ** 2/(2 * c1 ** 2))\n",
      "# Generating clean data\n",
      "x = np.\n",
      "linspace(0, 20, 200)\n",
      "y = func(x, 1, 3, 1, -2, 15, 0.\n",
      "5)\n",
      "# Adding noise to the data\n",
      "y n=y+0 .\n",
      " 2* np.\n",
      "random.\n",
      "normal(size=len(x))\n",
      "# Since we are fitting a more complex function,\n",
      "# providing guesses for the fitting will lead to\n",
      "# better results.\n",
      "\n",
      "guesses = [1, 3, 1, 1, 15, 1]\n",
      "# Executing curve_fit on noisy data\n",
      "popt, pcov = curve_fit(func, x, yn,\n",
      "p0=guesses)\n",
      "3.\n",
      "1.\n",
      "2 Solutions to Functions\n",
      "With data modeling and ﬁtting under our belts, we can move on to ﬁnding solutions,\n",
      "such as “What is the root of a function?” or “Where do two functions intersect?” SciPy\n",
      "provides an arsenal of tools to do this in the optimize module.\n",
      " We will run through the\n",
      "p r i m a r yo n e si nt h i ss e c t i o n .\n",
      "\n",
      "Let’ s start simply , by solving for the root of an equation (see Figure 3-4).\n",
      " Here we will\n",
      "usescipy.\n",
      "optimize.\n",
      "fsolve .\n",
      "\n",
      "20 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   28 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "29:\n",
      "Figure 3-4.\n",
      " Approximate the root of a linear function at y=0.\n",
      "\n",
      "from scipy.\n",
      "optimize import fsolve\n",
      "import numpy as np\n",
      "line = lambda x :x+3\n",
      "solution = fsolve(line, -2)\n",
      "print solution\n",
      "Finding the intersection points between two equations is nearly as simple.\n",
      "3\n",
      "from scipy.\n",
      "optimize import fsolve\n",
      "import numpy as np\n",
      "# Defining function to simplify intersection solution\n",
      "def findIntersection(func1, func2, x0):\n",
      "return fsolve(lambda x : func1(x) - func2(x), x0)\n",
      "# Defining functions that will intersect\n",
      "funky = lambda x : np.\n",
      "cos(x / 5) * np.\n",
      "sin(x / 2)\n",
      "line = lambd ax:0 .\n",
      " 0 1*x-0 .\n",
      " 5\n",
      "# Defining range and getting solutions on intersection points\n",
      "x = np.\n",
      "linspace(0,45,10000)\n",
      "result = findIntersection(funky, line, [15, 20, 30, 35, 40, 45])\n",
      "# Printing out results for x and y\n",
      "print(result, line(result))\n",
      "As we can see in Figure 3-5, the intersection points are well identiﬁed.\n",
      " Keep in mind\n",
      "that the assumptions about where the functions will intersect are important.\n",
      " If these\n",
      "are incorrect, you could get specious results.\n",
      "\n",
      "3This is a modiﬁed example from http://glowingpython.\n",
      "blogspot.\n",
      "de/201 1/05/hot-to-ﬁnd-intersection-of-two.\n",
      "html .\n",
      "\n",
      "3.\n",
      "1 Optimization and Minimization | 21\n",
      "9781449305468_text.\n",
      "pdf   29 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "30:\n",
      "Figure 3-5.\n",
      " Finding the intersection points between two functions.\n",
      "\n",
      "3.\n",
      "2 Interpolation\n",
      "Data that contains information usually has a functional form, and as analysts we want\n",
      "to model it.\n",
      " Given a set of sample data, obta ining the intermediate values between the\n",
      "points is useful to understand and predict what the data will do in the non-sampled do-\n",
      "main.\n",
      " SciPy offers well over a dozen different functions for interpolation, ranging from\n",
      "those for simple univariate cases to those for complex multivariate ones.\n",
      " Univariate\n",
      "interpolation is used when the sampled data is likely led by one independent vari-\n",
      "able, whereas multivariate interpolation assumes there is more than one independent\n",
      "variable.\n",
      "\n",
      "There are two basic methods of interpolation: (1) Fit one function to an entire dataset\n",
      "or (2) ﬁt different parts of the dataset with several functions where the joints of each\n",
      "function are joined smoothly .\n",
      " The second type is known as a spline interpolation, which\n",
      "can be a very powerful tool when the functional form of data is complex.\n",
      " We will\n",
      "ﬁrst show how to interpolate a simple function, and then proceed to a more complex\n",
      "case.\n",
      " The example below interpolates a sinusoidal function (see Figure 3-6) using\n",
      "scipy.\n",
      "interpolate.\n",
      "interp1d with different ﬁtting parameters.\n",
      " The ﬁrst parameter is a\n",
      "“linear” ﬁt and the second is a “quadratic” ﬁt.\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "interpolate import interp1d\n",
      "# Setting up fake data\n",
      "x = np.\n",
      "linspace(0, 10 * np.\n",
      "pi, 20)\n",
      "y = np.\n",
      "cos(x)\n",
      "# Interpolating data\n",
      "fl = interp1d(x, y, kind='linear')\n",
      "fq = interp1d(x, y, kind='quadratic')\n",
      "# x.\n",
      "min and x.\n",
      "max are used to make sure we do not\n",
      "# go beyond the boundaries of the data for the\n",
      "# interpolation.\n",
      "\n",
      "xint = np.\n",
      "linspace(x.\n",
      "min(), x.\n",
      "max(), 1000)\n",
      "yintl = fl(xint)\n",
      "yintq = fq(xint)\n",
      "22 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   30 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "31:\n",
      "Figure 3-6.\n",
      " Synthetic data points (red dots) interpolated with li near and quadratic parameters.\n",
      "\n",
      "Figure 3-7 .\n",
      " Interpolating noisy synthetic data.\n",
      "\n",
      "Figure 3-6 shows that in this case the quadratic ﬁt is far better.\n",
      " This\n",
      "should demonstrate how important it is to choose the proper parameters\n",
      "when interpolating data.\n",
      "\n",
      "Can we interpolate noisy data? Y es, and it is surprisingly easy , using a spline-ﬁtting\n",
      "function called scipy.\n",
      "interpolate.\n",
      "UnivariateSpline .\n",
      "( T h er e s u l ti ss h o w ni nF i g u r e\n",
      "3-7.\n",
      ")\n",
      "import numpy as np\n",
      "import matplotlib.\n",
      "pyplot as mpl\n",
      "from scipy.\n",
      "interpolate import UnivariateSpline\n",
      "# Setting up fake data with artificial noise\n",
      "sample = 30\n",
      "x = np.\n",
      "linspace(1, 10 * np.\n",
      "pi, sample)\n",
      "y = np.\n",
      "cos(x) + np.\n",
      "log10(x) + np.\n",
      "random.\n",
      "randn(sample) / 10\n",
      "# Interpolating the data\n",
      "f = UnivariateSpline(x, y, s=1)\n",
      "3.\n",
      "2 Interpolation | 23\n",
      "9781449305468_text.\n",
      "pdf   31 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "32:\n",
      "# x.\n",
      "min and x.\n",
      "max are used to make sure we do not\n",
      "# go beyond the boundaries of the data for the\n",
      "# interpolation.\n",
      "\n",
      "xint = np.\n",
      "linspace(x.\n",
      "min(), x.\n",
      "max(), 1000)\n",
      "yint = f(xint)\n",
      "The option sis the smoothing factor, which should be used when ﬁtting data with\n",
      "noise.\n",
      " If instead s=0, then the interpolation will go through all points while ignoring\n",
      "noise.\n",
      "\n",
      "Last but not least, we go over a multivariate example—in this case, to reproduce an\n",
      "image.\n",
      " The scipy.\n",
      "interpolate.\n",
      "griddata function is used for its capacity to deal with\n",
      "unstructured N-dimensional data.\n",
      " For example, if you have a 1000 ×1000-pixel image,\n",
      "and then randomly selected 1000 points, how well could you reconstruct the image?\n",
      "Refer to Figure 3-8 to see how well scipy.\n",
      "interpolate.\n",
      "griddata performs .\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "interpolate import griddata\n",
      "# Defining a function\n",
      "ripple = lambda x, y: np.\n",
      "sqrt(x**2 + y**2)+np.\n",
      "sin(x**2 + y**2)\n",
      "# Generating gridded data.\n",
      " The complex number defines\n",
      "# how many steps the grid data should have.\n",
      " Without the\n",
      "# complex number mgrid would only create a grid data structure\n",
      "# with 5 steps.\n",
      "\n",
      "grid_x, grid_y = np.\n",
      "mgrid[0:5:1000j, 0:5:1000j]\n",
      "# Generating sample that interpolation function will see\n",
      "xy = np.\n",
      "random.\n",
      "rand(1000, 2)\n",
      "sample = ripple(xy[:,0 ]*5, xy[:,1] * 5)\n",
      "# Interpolating data with a cubic\n",
      "grid_z0 = griddata(xy * 5, sample, (grid_x, grid_y), method='cubic')\n",
      "Figure 3-8.\n",
      " Original image with random sample (black points, left) and the interpolated image (right).\n",
      "\n",
      "24 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   32 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "33:\n",
      "On the left-hand side of Figure 3-8 is the original image; the black points are the\n",
      "randomly sampled positions.\n",
      " On the right-hand side is the interpolated image.\n",
      " There\n",
      "are some slight glitches that come from the sample being too sparse for the ﬁner\n",
      "structures.\n",
      " The only way to get a better interpolation is with a larger sample size.\n",
      " (Note\n",
      "that the griddata function has been recently added to SciPy and is only available for\n",
      "version 0.\n",
      "9 and beyond.\n",
      ")\n",
      "If we employ another multivariate spline interpolation, how would its results compare?\n",
      "Here we use scipy.\n",
      "interpolate.\n",
      "SmoothBivariateSpline , where the code is quite similar\n",
      "to that in the previous example.\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "interpolate import SmoothBivariateSpline as SBS\n",
      "# Defining a function\n",
      "ripple = lambda x, y: np.\n",
      "sqrt(x**2 + y**2)+np.\n",
      "sin(x**2 + y**2)\n",
      "# Generating sample that interpolation function will see\n",
      "xy= np.\n",
      "random.\n",
      "rand(1000, 2)\n",
      "x, y = xy[:,0], xy[:,1]\n",
      "sample = ripple(xy[:,0 ]*5, xy[:,1] * 5)\n",
      "# Interpolating data\n",
      "fit = SBS(x * 5 ,y*5 , sample, s=0.\n",
      "01, kx=4, ky=4)\n",
      "interp = fit(np.\n",
      "linspace(0, 5, 1000), np.\n",
      "linspace(0, 5, 1000))\n",
      "W e have a similar result to that in the last example (Figure 3-9).\n",
      " The left panel shows the\n",
      "original image with randomly sampled points, and in the right panel is the interpolated\n",
      "data.\n",
      " The SmoothBivariateSpline function appears to work a bit better than griddata ,\n",
      "with an exception in the upper-right corner.\n",
      "\n",
      "Figure 3-9.\n",
      " Original image with random sample (black points, left) and the interpolated image (right).\n",
      "\n",
      "3.\n",
      "2 Interpolation | 25\n",
      "9781449305468_text.\n",
      "pdf   33 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "34:\n",
      "Although from the ﬁgure SmoothBivariateSpline does appear to work\n",
      "better, run the code several times to see what happens.\n",
      " SmoothBivariate-\n",
      "Spline is very sensitive to the data sample it is given, and interpolations\n",
      "can go way off the mark.\n",
      " griddata is more robust and can produce a\n",
      "reasonable interpolation regardless of the data sample it is given.\n",
      "\n",
      "3.\n",
      "3 Integration\n",
      "Integration is a crucial tool in math and science, as differentiation and integration are\n",
      "the two key components of calculus.\n",
      " Given a curve from a function or a dataset, we\n",
      "can calculate the area below it.\n",
      " In the traditional classroom setting we would integrate\n",
      "a function analytically , but data in the research setting is rarely given in this form, and\n",
      "we need to approximate its deﬁnite integral.\n",
      "\n",
      "The main purpose of integration with SciPy is to obtain numerical solu-\n",
      "tions.\n",
      " If you need indeﬁnite integral solutions, then you should look at\n",
      "SymPy .\n",
      "4It solves mathematical problems symbolically for many types of\n",
      "computation beyond calculus.\n",
      "\n",
      "SciPy has a range of different functions to integrate equations and data.\n",
      " We will ﬁrst\n",
      "go over these functions, and then move on to the data solutions.\n",
      " Afterward, we will\n",
      "employ the data-ﬁtting tools we used earlier to compute deﬁnite integral solutions.\n",
      "\n",
      "3.\n",
      "3.\n",
      "1 Analytic Integration\n",
      "We will begin working with the function expressed below .\n",
      " It is straightforward to\n",
      "integrate and its solution’ s estimated error is small.\n",
      " See Figure 3-10 for the visual context\n",
      "of what is being calculated.\n",
      "\n",
      "/integraldisplay3\n",
      "0cos2(ex)dx (3.\n",
      " 1)\n",
      "import numpy as np\n",
      "from scipy.\n",
      "integrate import quad\n",
      "# Defining function to integrate\n",
      "func = lambda x: np.\n",
      "cos(np.\n",
      "exp(x)) ** 2\n",
      "# Integrating function with upper and lower\n",
      "# limits of 0 and 3, respectively\n",
      "solution = quad(func, 0, 3)\n",
      "print solution\n",
      "# The first element is the desired value\n",
      "# and the second is the error.\n",
      "\n",
      "# (1.\n",
      "296467785724373, 1.\n",
      "397797186265988e-09)\n",
      "4http://sympy.\n",
      "org/en/index.\n",
      "html\n",
      "26 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   34 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "35:\n",
      "Figure 3-10.\n",
      " Deﬁnite integral (shaded region) of a function.\n",
      "\n",
      "Figure 3-1 1.\n",
      " Deﬁnite integral (shaded region) of a function.\n",
      " The original function is the line and the\n",
      "randomly sampled data points are in red.\n",
      "\n",
      "3.\n",
      "3.\n",
      "2 Numerical Integration\n",
      "Let’ s move on to a problem where we are given data instead of some known equation\n",
      "and numerical integration is needed.\n",
      " Figure 3-1 1 illustrates what type of data sample\n",
      "can be used to approximate acceptable indeﬁnite integrals.\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "integrate import quad, trapz\n",
      "# Setting up fake data\n",
      "x = np.\n",
      "sort(np.\n",
      "random.\n",
      "randn(150 )*4+ 4).\n",
      "clip(0,5)\n",
      "func = lambda x: np.\n",
      "sin(x) * np.\n",
      "cos(x ** 2) + 1\n",
      "y = func(x)\n",
      "# Integrating function with upper and lower\n",
      "# limits of 0 and 5, respectively\n",
      "fsolution = quad(func, 0, 5)\n",
      "dsolution = trapz(y, x=x)\n",
      "3.\n",
      "3 Integration | 27\n",
      "9781449305468_text.\n",
      "pdf   35 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "36:\n",
      "print('fsolutio n='+ str(fsolution[0]))\n",
      "print('dsolutio n='+ str(dsolution))\n",
      "print('The difference is ' + str(np.\n",
      "abs(fsolution[0] - dsolution)))\n",
      "# fsolution = 5.\n",
      "10034506754\n",
      "# dsolution = 5.\n",
      "04201628314\n",
      "# The difference is 0.\n",
      "0583287843989.\n",
      "\n",
      "The quadintegrator can only work with a callable function, whereas trapz is a numerical\n",
      "integrator that utilizes data points.\n",
      "\n",
      "3.\n",
      "4 Statistics\n",
      "In NumPy there are basic statistical functions like mean,std,median ,argmax , and argmin .\n",
      "\n",
      "Moreover, the numpy.\n",
      "arrays have built-in methods that allow us to use most of the\n",
      "NumPy statistics easily .\n",
      "\n",
      "import numpy as np\n",
      "# Constructing a random array with 1000 elements\n",
      "x = np.\n",
      "random.\n",
      "randn(1000)\n",
      "# Calculating several of the built-in methods\n",
      "# that numpy.\n",
      "array has\n",
      "mean = x.\n",
      "mean()\n",
      "std = x.\n",
      "std()\n",
      "var = x.\n",
      "var()\n",
      "For quick calculations these methods are useful, but more is usually needed for quan-\n",
      "titative research.\n",
      " SciPy offers an extended collection of statistical tools such as distribu-\n",
      "tions (continuous or discrete) and functions.\n",
      " We will ﬁrst cover how to extrapolate the\n",
      "different types of distributions.\n",
      " Afterward, we will discuss the SciPy statistical functions\n",
      "used most often in various ﬁelds.\n",
      "\n",
      "3.\n",
      "4.\n",
      "1 Continuous and Discrete Distributions\n",
      "There are roughly 80 continuous distributions and over 10 discrete distributions.\n",
      "\n",
      "Twenty of the continuous functions are shown in Figure 3-12 as probability density\n",
      "functions (PDFs) to give a visual impression of what the scipy.\n",
      "stats package provides.\n",
      "\n",
      "These distributions are useful as random number generators, s imilar to the funct ions\n",
      "found in numpy.\n",
      "random .\n",
      " Y et the rich variety of functions SciPy provides stands in con-\n",
      "trast to the numpy.\n",
      "random functions, which are limited to uniform and Gaussian-like\n",
      "distributions.\n",
      "\n",
      "When we call a distribution from scipy.\n",
      "stats , we can extract its information in several\n",
      "ways: probability density functions (PDFs), cumulative distribution functions (CDFs),\n",
      "random variable samples (RVSs), percent point functions (PPFs), and more.\n",
      " So how do\n",
      "we set up SciPy to give us these distributions? Working with the classic normal function\n",
      "PDF=e(−x2/2)/√\n",
      "2π(3.\n",
      "2)\n",
      "28 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   36 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "37:\n",
      "Figure 3-12.\n",
      " A sample of 20 continuous distributions in SciPy.\n",
      "\n",
      "we demonstrate how to access the distribution.\n",
      "\n",
      "import numpy as np\n",
      "import scipy.\n",
      "stats import norm\n",
      "# Set up the sample range\n",
      "x = np.\n",
      "linspace(-5,5,1000)\n",
      "3.\n",
      "4 Statistics | 29\n",
      "9781449305468_text.\n",
      "pdf   37 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "38:\n",
      "# Here set up the parameters for the normal distribution,\n",
      "# where loc is the mean and scale is the standard deviation.\n",
      "\n",
      "dist = norm(loc=0, scale=1)\n",
      "# Retrieving norm's PDF and CDF\n",
      "pdf = dist.\n",
      "pdf(x)\n",
      "cdf = dist.\n",
      "cdf(x)\n",
      "# Here we draw out 500 random values from the norm.\n",
      "\n",
      "sample = dist.\n",
      "rvs(500)\n",
      "The distribution can be centered at a different point and scaled with the options locand\n",
      "scale as shown in the example.\n",
      " This works as easily with all distributions because of\n",
      "their functional behavior, so it is important to read the documentation5when necessary .\n",
      "\n",
      "In other cases one will need a discrete distribution like the Poisson, binomial, or geo-\n",
      "metric.\n",
      " Unlike continuous distributions, discrete distributions are useful for problems\n",
      "where a given number of events occur in a ﬁxed interval of time/space, the events occur\n",
      "with a known average rate, and each event is independent of the prior event.\n",
      "\n",
      "Equation 3.\n",
      "3 is the probability mass function (PMF) of the geometric distribution.\n",
      "\n",
      "PMF=(1−p)(k−1)p (3.\n",
      "3)\n",
      "import numpy as np\n",
      "from scipy.\n",
      "stats import geom\n",
      "# Here set up the parameters for the geometric distribution.\n",
      "\n",
      "p = 0.\n",
      "5\n",
      "dist = geom(p)\n",
      "# Set up the sample range.\n",
      "\n",
      "x = np.\n",
      "linspace(0, 5, 1000)\n",
      "# Retrieving geom's PMF and CDF\n",
      "pmf = dist.\n",
      "pmf(x)\n",
      "cdf = dist.\n",
      "cdf(x)\n",
      "# Here we draw out 500 random values.\n",
      "\n",
      "sample = dist.\n",
      "rvs(500)\n",
      "3.\n",
      "4.\n",
      "2 Functions\n",
      "There are more than 60 statistical functions in SciPy , which can be overwhe lming to\n",
      "digest if you simply are curious about what is available.\n",
      " The best way to t hink of\n",
      "the statistics functions is that they either describe or test samples—for example, the\n",
      "frequency of certain values or the Kolmogorov-Smirnov test, respectively .\n",
      "\n",
      "Since SciPy provides a large range of distributions, it would be great to take advantage\n",
      "of the ones we covered earlier.\n",
      " In the stats package, there are a number of functions\n",
      "5http://docs.\n",
      "scipy.\n",
      "org/doc/scipy/reference/stats.\n",
      "html\n",
      "30 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   38 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "39:\n",
      "such as kstest and normaltest that test samples.\n",
      " These distribution tests can be very\n",
      "helpful in dete rmining whether a sample comes from some particular distribution or\n",
      "not.\n",
      " Before applying these, be sure you have a good understanding of your data, to\n",
      "avoid misinterpreting the functions’ results.\n",
      "\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "# Generating a normal distribution sample\n",
      "# with 100 elements\n",
      "sample = np.\n",
      "random.\n",
      "randn(100)\n",
      "# normaltest tests the null hypothesis.\n",
      "\n",
      "out = stats.\n",
      "normaltest(sample)\n",
      "print('normaltest output')\n",
      "print('Z-scor e='+ str(out[0]))\n",
      "print('P-valu e='+ str(out[1]))\n",
      "# kstest is the Kolmogorov-Smirnov test for goodness of fit.\n",
      "\n",
      "# Here its sample is being tested against the normal distribution.\n",
      "\n",
      "# D is the KS statistic and the closer it is to 0 the better.\n",
      "\n",
      "out = stats.\n",
      "kstest(sample, 'norm')\n",
      "print('\\nkstest output for the Normal distribution')\n",
      "print(' D='+ str(out[0]))\n",
      "print('P-valu e='+ str(out[1]))\n",
      "# Similarly, this can be easily tested against other distributions,\n",
      "# like the Wald distribution.\n",
      "\n",
      "out = stats.\n",
      "kstest(sample, 'wald')\n",
      "print('\\nkstest output for the Wald distribution')\n",
      "print(' D='+ str(out[0]))\n",
      "print('P-valu e='+ str(out[1]))\n",
      "Researchers commonly use descriptive functions for statistics.\n",
      " Some descriptive func-\n",
      "tions that are available in the stats package include the geometric mean ( gmean ), the\n",
      "skewness of a sample ( skew), and the frequency of values in a sample ( itemfreq ).\n",
      " Using\n",
      "these functions is simple and does not require much input.\n",
      " A few examples follow .\n",
      "\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "# Generating a normal distribution sample\n",
      "# with 100 elements\n",
      "sample = np.\n",
      "random.\n",
      "randn(100)\n",
      "# The harmonic mean: Sample values have to\n",
      "# be greater than 0.\n",
      "\n",
      "out = stats.\n",
      "hmean(sample[sample > 0])\n",
      "print('Harmonic mea n='+ str(out))\n",
      "# The mean, where values below -1 and above 1 are\n",
      "# removed for the mean calculation\n",
      "out = stats.\n",
      "tmean(sample, limits=(-1, 1))\n",
      "print('\\nTrimmed mea n='+ str(out))\n",
      "3.\n",
      "4 Statistics | 31\n",
      "9781449305468_text.\n",
      "pdf   39 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "40:\n",
      "# Calculating the skewness of the sample\n",
      "out = stats.\n",
      "skew(sample)\n",
      "print('\\nSkewnes s='+ str(out))\n",
      "# Additionally, there is a handy summary function called\n",
      "# describe, which gives a quick look at the data.\n",
      "\n",
      "out = stats.\n",
      "describe(sample)\n",
      "print('\\nSiz e='+ str(out[0]))\n",
      "print('Mi n='+ str(out[1][0]))\n",
      "print('Ma x='+ str(out[1][1]))\n",
      "print('Mea n='+ str(out[2]))\n",
      "print('Varianc e='+ str(out[3]))\n",
      "print('Skewnes s='+ str(out[4]))\n",
      "print('Kurtosi s='+ str(out[5]))\n",
      "There are many more functions available in the stats package, so the documentation\n",
      "is worth a look if you need more speciﬁc tools.\n",
      " If you need more statistical tools than\n",
      "are available here, try RPy .\n",
      "6R is a cornerstone package for statistical analysis, and RPy\n",
      "ports the tools available in that system to Python.\n",
      " If you’re content with what is available\n",
      "in SciPy and NumPy but need more automated analysis, then take a look at Pandas.\n",
      "7It\n",
      "is a powerful package that can perform quick statistical analysis on big data.\n",
      " Its output\n",
      "is supplied in both numerical values and plots.\n",
      "\n",
      "3.\n",
      "5 Spatial and Clustering Analysis\n",
      "From biological to astrophysical sciences, spatial and clustering analysis are key to iden-\n",
      "tifying patterns, groups, and clusters.\n",
      " In biology , for example, the spacing of different\n",
      "plant species hints at how seeds are dispersed, interact with the environment, and grow .\n",
      "\n",
      "In astrophysics, these analysis techniques are used to seek and identify star clusters,\n",
      "galaxy clusters, and large-scale ﬁlaments (composed of galaxy clusters).\n",
      " In the computer\n",
      "science domain, identifying and mapping complex networks of nodes and information\n",
      "is a vital study all on its own.\n",
      " With big data and data mining, identifying data clusters\n",
      "is becoming important, in order to organize discovered information, rather than being\n",
      "overwhelmed by it.\n",
      "\n",
      "If you need a package that provides good graph theory capabilities, check\n",
      "out NetworkX.\n",
      "8It is an excellent Python package for creating, modu-\n",
      "lating, and studying the structure of complex networks (i.\n",
      "e.\n",
      ", minimum\n",
      "spanning trees analysis).\n",
      "\n",
      "SciPy provides a spatial analysis class ( scipy.\n",
      "spatial ) and a cluster analysis class\n",
      "(scipy.\n",
      "cluster ).\n",
      " The spatial class includes functions to analyze distances between data\n",
      "points (e.\n",
      "g.\n",
      ", k-d trees).\n",
      " The cluster class provides two overarching subclasses: vector\n",
      "quantization ( vq) and hierarchical clustering ( hierarchy ).\n",
      " Vector quantization groups\n",
      "6http://rpy.\n",
      "sourceforge.\n",
      "net/\n",
      "7http://pandas.\n",
      "pydata.\n",
      "org/\n",
      "8http://networkx.\n",
      "lanl.\n",
      "gov/\n",
      "32 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   40 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "41:\n",
      "large sets of data points (vectors) where each group is represented by centroids.\n",
      " The\n",
      "hierarchy subclass contains functions to construct clusters and analyze their substruc-\n",
      "tures.\n",
      "\n",
      "3.\n",
      "5.\n",
      "1 Vector Quantization\n",
      "Vector quantization is a general term that can be associated with signal processing, data\n",
      "compression, and clustering.\n",
      " Here we will focus on the clustering component, starting\n",
      "with how to feed data to the vqpackage in order to identify clusters.\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "cluster import vq\n",
      "# Creating data\n",
      "c1 = np.\n",
      "random.\n",
      "randn(100, 2) + 5\n",
      "c2 = np.\n",
      "random.\n",
      "randn(30, 2) - 5\n",
      "c3 = np.\n",
      "random.\n",
      "randn(50, 2)\n",
      "# Pooling all the data into one 180 x 2 array\n",
      "data = np.\n",
      "vstack([c1, c2, c3])\n",
      "# Calculating the cluster centroids and variance\n",
      "# from kmeans\n",
      "centroids, variance = vq.\n",
      "kmeans(data, 3)\n",
      "# The identified variable contains the information\n",
      "# we need to separate the points in clusters\n",
      "# based on the vq function.\n",
      "\n",
      "identified, distance = vq.\n",
      "vq(data, centroids)\n",
      "# Retrieving coordinates for points in each vq\n",
      "# identified core\n",
      "vqc1 = data[identified == 0]\n",
      "vqc2 = data[identified == 1]\n",
      "vqc3 = data[identified == 2]\n",
      "The result of the identiﬁed clusters matches up quite well to the original data, as shown\n",
      "in Figure 3-13 (the generated cluster data is on the left and the vq-identiﬁed clusters are\n",
      "the on the right).\n",
      " But this was done only for data that had little noise.\n",
      " What happens if\n",
      "there is a randomly distributed set of points in the ﬁeld? The algorithm fails with ﬂying\n",
      "colors.\n",
      " See Figure 3-1 4 for a nice illustration of this.\n",
      "\n",
      "3.\n",
      "5.\n",
      "2 Hierarchical Clustering\n",
      "Hierarchical clustering is a powerful tool for identifying structures that are nested\n",
      "within larger structures.\n",
      " But working with the output can be tricky , as we do not get\n",
      "cleanly identiﬁed clusters like we do with the kmeans technique.\n",
      " Below is an example9\n",
      "wherein we generate a system of multiple clusters.\n",
      " T o employ the hierarchy function,\n",
      "9The original effort in using this can be found at http://stackoverﬂow.\n",
      "com/questions/2982929/plotting-results-\n",
      "of-hierarchical-clustering-ontop-of-a-matrix-of-data-in-python .\n",
      "\n",
      "3.\n",
      "5 Spatial and Clustering Analysis | 33\n",
      "9781449305468_text.\n",
      "pdf   41 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "42:\n",
      "Figure 3-1 3.\n",
      " Original clusters (left) and vq.\n",
      "kmeans -identiﬁed clusters (right).\n",
      " Points are associated to\n",
      "a cluster by color .\n",
      "\n",
      "Figure 3-1 4.\n",
      " Original clusters (left) and vq.\n",
      "kmeans -identiﬁed clusters (right).\n",
      " Points are associated to\n",
      "a cluster by color .\n",
      " The uniformly distributed data shows the weak point of the vq.\n",
      "kmeans function.\n",
      "\n",
      "we build a distance matrix, and the output is a dendrogram tree.\n",
      " See Figure 3-15 for a\n",
      "visual example of how hierarchical clustering works.\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.\n",
      "pyplot as mpl\n",
      "from mpl_toolkits.\n",
      "mplot3d import Axes3D\n",
      "from scipy.\n",
      "spatial.\n",
      "distance import pdist, squareform\n",
      "import scipy.\n",
      "cluster.\n",
      "hierarchy as hy\n",
      "# Creating a cluster of clusters function\n",
      "def clusters(number = 20, cnumber = 5, csize = 10):\n",
      "# Note that the way the clusters are positioned is Gaussian randomness.\n",
      "\n",
      "rnum = np.\n",
      "random.\n",
      "rand(cnumber, 2)\n",
      "rn = rnum[:,0] * number\n",
      "rn = rn.\n",
      "astype(int)\n",
      "rn[np.\n",
      "where(r n<5) ]=5\n",
      "rn[np.\n",
      "where(rn > number/2.\n",
      " )] = round(number / 2.\n",
      ", 0)\n",
      "34 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   42 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "43:\n",
      "Figure 3-1 5.\n",
      " The pixelated subplot is the distance matrix, and the two dendrogram subplots show\n",
      "different types of dendrogram methods.\n",
      "\n",
      "ra = rnum[:,1] * 2.\n",
      "9\n",
      "ra[np.\n",
      "where(ra < 1.\n",
      "5)] = 1.\n",
      "5\n",
      "cls = np.\n",
      "random.\n",
      "randn(number, 3) * csize\n",
      "# Random multipliers for central point of cluster\n",
      "rxyz = np.\n",
      "random.\n",
      "randn(cnumber-1, 3)\n",
      "for i in xrange(cnumber-1):\n",
      "tmp = np.\n",
      "random.\n",
      "randn(rn[i+1], 3)\n",
      "x = tmp[:,0] + ( rxyz[i,0] * csize )\n",
      "y = tmp[:,1] + ( rxyz[i,1] * csize )\n",
      "z = tmp[:,2] + ( rxyz[i,2] * csize )\n",
      "tmp = np.\n",
      "column_stack([x,y,z])\n",
      "cls = np.\n",
      "vstack([cls,tmp])\n",
      "return cls\n",
      "3.\n",
      "5 Spatial and Clustering Analysis | 35\n",
      "9781449305468_text.\n",
      "pdf   43 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "44:\n",
      "# Generate a cluster of clusters and distance matrix.\n",
      "\n",
      "cls = clusters()\n",
      "D = pdist(cls[:,0:2])\n",
      "D = squareform(D)\n",
      "# Compute and plot first dendrogram.\n",
      "\n",
      "fig = mpl.\n",
      "figure(figsize=(8,8))\n",
      "ax1 = fig.\n",
      "add_axes([0.\n",
      "09,0.\n",
      "1,0.\n",
      "2,0.\n",
      "6])\n",
      "Y1 = hy.\n",
      "linkage(D, method='complete')\n",
      "cutoff = 0.\n",
      "3 * np.\n",
      "max(Y1[:, 2])\n",
      "Z1 = hy.\n",
      "dendrogram(Y1, orientation='right', color_threshold=cutoff)\n",
      "ax1.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax1.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "# Compute and plot second dendrogram.\n",
      "\n",
      "ax2 = fig.\n",
      "add_axes([0.\n",
      "3,0.\n",
      "71,0.\n",
      "6,0.\n",
      "2])\n",
      "Y2 = hy.\n",
      "linkage(D, method='average')\n",
      "cutoff = 0.\n",
      "3 * np.\n",
      "max(Y2[:, 2])\n",
      "Z2 = hy.\n",
      "dendrogram(Y2, color_threshold=cutoff)\n",
      "ax2.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax2.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "# Plot distance matrix.\n",
      "\n",
      "ax3 = fig.\n",
      "add_axes([0.\n",
      "3,0.\n",
      "1,0.\n",
      "6,0.\n",
      "6])\n",
      "idx1 = Z1['leaves']\n",
      "idx2 = Z2['leaves']\n",
      "D = D[idx1,:]\n",
      "D = D[:,idx2]\n",
      "ax3.\n",
      "matshow(D, aspect='auto', origin='lower', cmap=mpl.\n",
      "cm.\n",
      "YlGnBu)\n",
      "ax3.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax3.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "# Plot colorbar.\n",
      "\n",
      "fig.\n",
      "savefig('cluster_hy_f01.\n",
      "pdf', bbox = 'tight')\n",
      "Seeing the distance matrix in the ﬁgure with the dendrogram tree highlights how the\n",
      "large and small structures are identiﬁed.\n",
      " The question is, how do we distinguish the\n",
      "structures from one another? Here we use a function called fcluster that provides us\n",
      "with the indices to each of the clusters at some threshold.\n",
      " The output from fcluster will\n",
      "depend on the method you use when calculating the linkage function, such as complete\n",
      "orsingle .\n",
      " The cutoff value you assign to the cluster is given as the second input in the\n",
      "fcluster function.\n",
      " In the dendrogram function, the cutoff’ s default is 0.\n",
      "7 * np.\n",
      "max(Y[:,\n",
      "2]), but here we will use the same cutoff as in the previous example, with the scaler 0.\n",
      "3.\n",
      "\n",
      "# Same imports and cluster function from the previous example\n",
      "# follow through here.\n",
      "\n",
      "# Here we define a function to collect the coordinates of\n",
      "# each point of the different clusters.\n",
      "\n",
      "def group(data, index):\n",
      "number = np.\n",
      "unique(index)\n",
      "groups = []\n",
      "for i in number:\n",
      "groups.\n",
      "append(data[index == i])\n",
      "return groups\n",
      "36 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   44 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "45:\n",
      "# Creating a cluster of clusters\n",
      "cls = clusters()\n",
      "# Calculating the linkage matrix\n",
      "Y = hy.\n",
      "linkage(cls[:,0:2], method='complete')\n",
      "# Here we use the fcluster function to pull out a\n",
      "# collection of flat clusters from the hierarchical\n",
      "# data structure.\n",
      " Note that we are using the same\n",
      "# cutoff value as in the previous example for the dendrogram\n",
      "# using the 'complete' method.\n",
      "\n",
      "cutoff = 0.\n",
      "3 * np.\n",
      "max(Y[:, 2])\n",
      "index = hy.\n",
      "fcluster(Y, cutoff, 'distance')\n",
      "# Using the group function, we group points into their\n",
      "# respective clusters.\n",
      "\n",
      "groups = group(cls, index)\n",
      "# Plotting clusters\n",
      "fig = mpl.\n",
      "figure(figsize=(6, 6))\n",
      "ax = fig.\n",
      "add_subplot(111)\n",
      "colors = ['r', 'c', 'b', 'g', 'orange', 'k', 'y', 'gray']\n",
      "for i, g in enumerate(groups):\n",
      "i = np.\n",
      "mod(i, len(colors))\n",
      "ax.\n",
      "scatter(g[:,0], g[:,1], c=colors[i], edgecolor='none', s=50)\n",
      "ax.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "fig.\n",
      "savefig('cluster_hy_f02.\n",
      "pdf', bbox = 'tight')\n",
      "The hierarchically identiﬁed clusters are shown in Figure 3-16.\n",
      "\n",
      "Figure 3-16.\n",
      " Hierarchically identiﬁed clusters.\n",
      "\n",
      "3.\n",
      "5 Spatial and Clustering Analysis | 37\n",
      "9781449305468_text.\n",
      "pdf   45 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "46:\n",
      "Figure 3-1 7 .\n",
      " A stacked image that is composed of hundreds of exposures from the International Space\n",
      "Station.\n",
      "\n",
      "3.\n",
      "6 Signal and Image Processing\n",
      "SciPy allows us to read and write image ﬁles like JPEG and PNG images without\n",
      "worrying too much about the ﬁle structure for color images.\n",
      " Below , we run through a\n",
      "simple illustration of working with image ﬁles to make a nice image10(see Figure 3-1 7)\n",
      "from the International Space Station (ISS).\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "misc import imread, imsave\n",
      "from glob import glob\n",
      "# Getting the list of files in the directory\n",
      "files = glob('space/*.\n",
      "JPG')\n",
      "# Opening up the first image for loop\n",
      "im1 = imread(files[0]).\n",
      "astype(np.\n",
      "float32)\n",
      "# Starting loop and continue co-adding new images\n",
      "for i in xrange(1, len(files)):\n",
      "print i\n",
      "im1 += imread(files[i]).\n",
      "astype(np.\n",
      "float32)\n",
      "# Saving img\n",
      "imsave('stacked_image.\n",
      "jpg', im1)\n",
      "10Original Pythonic effort can be found at http://stackoverﬂow.\n",
      "com/questions/925 1 580/stacking-astronomy-\n",
      "images-with-python .\n",
      "\n",
      "38 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   46 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "47:\n",
      "Figure 3-18.\n",
      " A stacked image that is composed of hundreds of exposures from the International Space\n",
      "Station.\n",
      "\n",
      "The JPG images in the Python environment are NumPy arrays with (426, 640, 3) ,\n",
      "where the three layers are red, green, and blue, respectively .\n",
      "\n",
      "In the original stacked image, seeing the star trails above Earth is nearly impossible.\n",
      "\n",
      "We modify the previous example to enhance the star trails as shown in Figure 3-18.\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "misc import imread, imsave\n",
      "from glob import glob\n",
      "# This function allows us to place in the\n",
      "# brightest pixels per x and y position between\n",
      "# two images.\n",
      " It is similar to PIL's\n",
      "# ImageChop.\n",
      "Lighter function.\n",
      "\n",
      "def chop_lighter(image1, image2):\n",
      "s1 = np.\n",
      "sum(image1, axis=2)\n",
      "s2 = np.\n",
      "sum(image2, axis=2)\n",
      "index = s1 < s2\n",
      "image1[index, 0] = image2[index, 0]\n",
      "image1[index, 1] = image2[index, 1]\n",
      "image1[index, 2] = image2[index, 2]\n",
      "return image1\n",
      "# Getting the list of files in the directory\n",
      "files = glob('space/*.\n",
      "JPG')\n",
      "# Opening up the first image for looping\n",
      "im1 = imread(files[0]).\n",
      "astype(np.\n",
      "float32)\n",
      "im2 = np.\n",
      "copy(im1)\n",
      "3.\n",
      "6 Signal and Image Processing | 39\n",
      "9781449305468_text.\n",
      "pdf   47 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "48:\n",
      "# Starting loop\n",
      "for i in xrange(1, len(files)):\n",
      "print i\n",
      "im = imread(files[i]).\n",
      "astype(np.\n",
      "float32)\n",
      "# Same before\n",
      "im1 += im\n",
      "# im2 shows star trails better\n",
      "im2 = chop_lighter(im2, im)\n",
      "# Saving image with slight tweaking on the combination\n",
      "# of the two images to show star trails with the\n",
      "# co-added image.\n",
      "\n",
      "imsave('stacked_image.\n",
      "jpg', im1/im1.\n",
      "max() + im2/im2.\n",
      "max()*0.\n",
      "2)\n",
      "When dealing with images without SciPy , you have to be more c oncerned about k eeping\n",
      "the array values in the right format when saving them as image ﬁles.\n",
      " SciPy deals with\n",
      "that nicely and allows us to focus on processing the images and obtaining our desired\n",
      "effects.\n",
      "\n",
      "3.\n",
      "7 Sparse Matrices\n",
      "With NumPy we can operate with reasonable speeds on arrays conta ining 106elements.\n",
      "\n",
      "Once we go up to 107elements, operations can start to slow down and Python’ s memory\n",
      "will become limited, de pending on the amount of RAM available.\n",
      " What’ s the best\n",
      "solution if you need to work with an array that is far larger—say , 1010elements? If\n",
      "these massive arrays primarily contain zeros, then you’re in luck, as this is the property\n",
      "ofsparse matrices .\n",
      " If a sparse matrix is treated correctly , operation time and memory\n",
      "usage can go down drastically .\n",
      " The simple example below illustrates this.\n",
      "\n",
      "Y ou can determine the byte size of a numpy.\n",
      "array by calling its method\n",
      "nbytes .\n",
      " This can be especially useful when trying to dete rmine what is\n",
      "hogging memory in your code.\n",
      " T o do the same with sparse matrices, you\n",
      "can use data.\n",
      "nbytes .\n",
      "\n",
      "import numpy as np\n",
      "from scipy.\n",
      "sparse.\n",
      "linalg import eigsh\n",
      "from scipy.\n",
      "linalg import eigh\n",
      "import scipy.\n",
      "sparse\n",
      "import time\n",
      "N = 3000\n",
      "# Creating a random sparse matrix\n",
      "m = scipy.\n",
      "sparse.\n",
      "rand(N, N)\n",
      "# Creating an array clone of it\n",
      "a = m.\n",
      "toarray()\n",
      "print('The numpy array data size: ' + str(a.\n",
      "nbytes) + ' bytes')\n",
      "print('The sparse matrix data size: ' + str(m.\n",
      "data.\n",
      "nbytes) + ' bytes')\n",
      "# Non-sparse\n",
      "t0 = time.\n",
      "time()\n",
      "40 | Chapter 3: SciPy\n",
      "9781449305468_text.\n",
      "pdf   48 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "49:\n",
      "res1 = eigh(a)\n",
      "dt = str(np.\n",
      "round(time.\n",
      "time() - t0, 3)) + ' seconds'\n",
      "print('Non-sparse operation take s'+d t )\n",
      "# Sparse\n",
      "t0 = time.\n",
      "time()\n",
      "res2 = eigsh(m)\n",
      "dt = str(np.\n",
      "round(time.\n",
      "time() - t0, 3)) + ' seconds'\n",
      "print('Sparse operation take s'+d t )\n",
      "The memory allotted to the NumPy array and sparse matrix were 68 MB and 0.\n",
      "68 MB,\n",
      "respectively .\n",
      " In the same order, the times taken to process the Eigen commands were\n",
      "36.\n",
      "6 and 0.\n",
      "2 seconds on my computer.\n",
      " This means that the sparse matrix was 100 times\n",
      "more memory efﬁcient and the Eigen operation was roughly 150 times faster than the\n",
      "non-sparse cases.\n",
      "\n",
      "If you’re unfamiliar with sparse matrices, I suggest reading http://www\n",
      ".\n",
      "scipy.\n",
      "org/SciPyPackages/Sparse , where the basics on sparse matrices and\n",
      "operations are discussed.\n",
      "\n",
      "In 2D and 3D geometry , there are many sparse data structures used in ﬁelds like\n",
      "engineering, computational ﬂuid dynamics, electromagnetism, thermodynamics, and\n",
      "acoustics.\n",
      " Non-geometric instances of sparse matrices are applicable to optimization,\n",
      "economic modeling, mathematics and statistics, and network/graph theories.\n",
      "\n",
      "Using scipy.\n",
      "io , you can read and write common sparse matrix ﬁle formats such as\n",
      "Matrix Market and Harwell-Boeing, or load MatLab ﬁles.\n",
      " This is especially useful for\n",
      "collaborations with others who use these data formats.\n",
      " In the next section, we expand\n",
      "on these scipy.\n",
      "io capabilities.\n",
      "\n",
      "3.\n",
      "8 Reading and Writing Files Beyond NumPy\n",
      "NumPy provides a good set of input and output capabilities with ASCII ﬁles.\n",
      " Its binary\n",
      "support is great if you only need to share information to be read from one Python\n",
      "environment to another.\n",
      " But what about more universally used binary ﬁle formats?\n",
      "If you are using Matlab or collaborating with others who are using it, then as brieﬂy\n",
      "mentioned in the previous section, it is not a problem for NumPy to read and write\n",
      "Matlab-supported ﬁles (using scipy.\n",
      "io.\n",
      "loadmat and scipy.\n",
      "savemat ).\n",
      "\n",
      "In ﬁelds like astronomy , geography , and medicine, there is a progra mming language\n",
      "called IDL.\n",
      " It saves ﬁles in a binary format and can be read by NumPy using a built-in\n",
      "package called scipy.\n",
      "io.\n",
      "readsav .\n",
      " It is a ﬂexible and fast module, but it does not have\n",
      "writing capabilities.\n",
      "\n",
      "Last but not least, you can qu ery , read, and write M atrix Market ﬁles.\n",
      " These are very\n",
      "commonly used to share matrix data structures that are written in ASCII format.\n",
      " This\n",
      "format is well supported in other languages like C, Fortran, and Matlab, so it is a good\n",
      "format to use due to its universality and user readability .\n",
      " It is also suitable for sparse\n",
      "matrices.\n",
      "\n",
      "3.\n",
      "8 Reading and Writing Files Beyond NumPy | 41\n",
      "9781449305468_text.\n",
      "pdf   49 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "50:\n",
      "9781449305468_text.\n",
      "pdf   50 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "51:\n",
      "CHAPTER 4\n",
      "SciKit: Taking SciPy One Step Further\n",
      "SciPy and NumPy are great tools and provide us with most of the functionality that we\n",
      "need.\n",
      " Sometimes, though we need more advanced tools, and that’ s where the scikits\n",
      "come in.\n",
      " These are a set of packages that are complementary to SciPy .\n",
      " There are\n",
      "currently more than 20 scikit packages available; a list can be found at http://scikit\n",
      ".\n",
      "appspot.\n",
      "com/ .\n",
      " Here we will go over two well-maintained and popular packages: Scikit-\n",
      "image, a more beefed-up image module than scipy.\n",
      "ndimage , is aimed to be an imaging\n",
      "processing toolkit for SciPy .\n",
      " Scikit-learn is a machine lea rning package that can be used\n",
      "for a range of scientiﬁc and engineering purposes.\n",
      "\n",
      "4.\n",
      "1 Scikit-Image\n",
      "SciPy’ s ndimage class contains many useful tools for processing multi-dimensional data,\n",
      "such as basic ﬁltering (e.\n",
      "g.\n",
      ", Gaussian smoothing), Fourier transform, morphology (e.\n",
      "g.\n",
      ",\n",
      "binary erosion), interpolation, and measurements.\n",
      " From those functions we can write\n",
      "programs to execute more complex operations.\n",
      " Scikit-image has fortunately taken on\n",
      "the task of going a step further to provide more advanced functions that we may\n",
      "need for scientiﬁc research.\n",
      " These advanced and high-level modules include color\n",
      "space conversion, image intensity adjustment algorithms, feature detections, ﬁlters for\n",
      "sharpening and denoising, read/write capabilities, and more.\n",
      "\n",
      "4.\n",
      "1.\n",
      "1 Dynamic Threshold\n",
      "A common application in imaging science is segmenting image components from one\n",
      "another, which is referred to as thresholding.\n",
      " The classic thresholding technique works\n",
      "well when the background of the image is ﬂat.\n",
      " Unfortunately , this situation is not the\n",
      "norm; instead, the background visually will be changing throughout the image.\n",
      " Hence,\n",
      "adaptive thresholding techniques have been developed, and we can easily ut ilize them\n",
      "in scikit-image.\n",
      " In the following example, we generate an image with a non-uniform\n",
      "background that has randomly placed fuzzy dots throughout (see Figure 4-1).\n",
      " Then\n",
      "43\n",
      "9781449305468_text.\n",
      "pdf   51 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "52:\n",
      "Figure 4-1.\n",
      " Illustration of thresholding.\n",
      " The original synthetic image is on the left, with classic and\n",
      "dynamic threshold algorithms at work from middle to right, respectively.\n",
      "\n",
      "we run a basic and adaptive threshold function on the image to see how well we can\n",
      "segment the fuzzy dots from the background.\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.\n",
      "pyplot as mpl\n",
      "import scipy.\n",
      "ndimage as ndimage\n",
      "import skimage.\n",
      "filter as skif\n",
      "# Generating data points with a non-uniform background\n",
      "x = np.\n",
      "random.\n",
      "uniform(low=0, high=100, size=20).\n",
      "astype(int)\n",
      "y = np.\n",
      "random.\n",
      "uniform(low=0, high=100, size=20).\n",
      "astype(int)\n",
      "# Creating image with non-uniform background\n",
      "func = lambda x, y: x**2 + y**2\n",
      "grid_x, grid_y = np.\n",
      "mgrid[-1:1:100j, -2:2:100j]\n",
      "bkg = func(grid_x, grid_y)\n",
      "bkg = bkg / np.\n",
      "max(bkg)\n",
      "# Creating points\n",
      "clean = np.\n",
      "zeros((100,100))\n",
      "clean[(x,y)] += 5\n",
      "clean = ndimage.\n",
      "gaussian_filter(clean, 3)\n",
      "clean = clean / np.\n",
      "max(clean)\n",
      "# Combining both the non-uniform background\n",
      "# and points\n",
      "fimg = bkg + clean\n",
      "fimg = fimg / np.\n",
      "max(fimg)\n",
      "# Defining minimum neighboring size of objects\n",
      "block_size = 3\n",
      "# Adaptive threshold function which returns image\n",
      "# map of structures that are different relative to\n",
      "# background\n",
      "adaptive_cut = skif.\n",
      "threshold_adaptive(fimg, block_size, offset=0)\n",
      "44 | Chapter 4: SciKit: Taking SciPy One Step Further\n",
      "9781449305468_text.\n",
      "pdf   52 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "53:\n",
      "# Global threshold\n",
      "global_thresh = skif.\n",
      "threshold_otsu(fimg)\n",
      "global_cut = fimg > global_thresh\n",
      "# Creating figure to highlight difference between\n",
      "# adaptive and global threshold methods\n",
      "fig = mpl.\n",
      "figure(figsize=(8, 4))\n",
      "fig.\n",
      "subplots_adjust(hspace=0.\n",
      "05, wspace=0.\n",
      "05)\n",
      "ax1 = fig.\n",
      "add_subplot(131)\n",
      "ax1.\n",
      "imshow(fimg)\n",
      "ax1.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax1.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "ax2 = fig.\n",
      "add_subplot(132)\n",
      "ax2.\n",
      "imshow(global_cut)\n",
      "ax2.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax2.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "ax3 = fig.\n",
      "add_subplot(133)\n",
      "ax3.\n",
      "imshow(adaptive_cut)\n",
      "ax3.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax3.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "fig.\n",
      "savefig('scikit_image_f01.\n",
      "pdf', bbox_inches='tight')\n",
      "In this case, as shown in Figure 4-1, the adaptive thresholding technique (right panel)\n",
      "obviously works far better than the basic one (middle panel).\n",
      " Most of the code above\n",
      "is for generating the image and plotting the output for context.\n",
      " The actual code for\n",
      "adaptively thresholding the image took only two lines.\n",
      "\n",
      "4.\n",
      "1.\n",
      "2 Local Maxima\n",
      "Approaching a slightly different problem, but with a s imilar setup as before, how can\n",
      "we identify points on a non-uniform background to obtain their pixel coordinates?\n",
      "Here we can use skimage.\n",
      "morphology.\n",
      "is_local_maximum , which only needs the image\n",
      "as a default input.\n",
      " The function works surprisingly well; see Figure 4-2, where the\n",
      "identiﬁed maxima are circled in blue.\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.\n",
      "pyplot as mpl\n",
      "import scipy.\n",
      "ndimage as ndimage\n",
      "import skimage.\n",
      "morphology as morph\n",
      "# Generating data points with a non-uniform background\n",
      "x = np.\n",
      "random.\n",
      "uniform(low=0, high=200, size=20).\n",
      "astype(int)\n",
      "y = np.\n",
      "random.\n",
      "uniform(low=0, high=400, size=20).\n",
      "astype(int)\n",
      "# Creating image with non-uniform background\n",
      "func = lambda x, y: np.\n",
      "cos(x)+ np.\n",
      "sin(y)\n",
      "grid_x, grid_y = np.\n",
      "mgrid[0:12:200j, 0:24:400j]\n",
      "bkg = func(grid_x, grid_y)\n",
      "bkg = bkg / np.\n",
      "max(bkg)\n",
      "4.\n",
      "1 Scikit-Image | 45\n",
      "9781449305468_text.\n",
      "pdf   53 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "54:\n",
      "Figure 4-2.\n",
      " Identiﬁed local maxima (blue circles).\n",
      "\n",
      "# Creating points\n",
      "clean = np.\n",
      "zeros((200,400))\n",
      "clean[(x,y)] += 5\n",
      "clean = ndimage.\n",
      "gaussian_filter(clean, 3)\n",
      "clean = clean / np.\n",
      "max(clean)\n",
      "# Combining both the non-uniform background\n",
      "# and points\n",
      "fimg = bkg + clean\n",
      "fimg = fimg / np.\n",
      "max(fimg)\n",
      "# Calculating local maxima\n",
      "lm1 = morph.\n",
      "is_local_maximum(fimg)\n",
      "x1, y1 = np.\n",
      "where(lm1.\n",
      "T == True)\n",
      "# Creating figure to show local maximum detection\n",
      "# rate success\n",
      "fig = mpl.\n",
      "figure(figsize=(8, 4))\n",
      "ax = fig.\n",
      "add_subplot(111)\n",
      "ax.\n",
      "imshow(fimg)\n",
      "ax.\n",
      "scatter(x1, y1, s=100, facecolor='none', edgecolor='#009999')\n",
      "ax.\n",
      "set_xlim(0,400)\n",
      "ax.\n",
      "set_ylim(0,200)\n",
      "ax.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "fig.\n",
      "savefig('scikit_image_f02.\n",
      "pdf', bbox_inches='tight')\n",
      "If you look closely at the ﬁgure, you will notice that there are identiﬁed maxima that\n",
      "do not point to fuzzy sources but instead to the background peaks.\n",
      " These peaks are a\n",
      "problem, but by deﬁnition this is what skimage.\n",
      "morphology.\n",
      "is_local_maximum will ﬁnd.\n",
      "\n",
      "How can we ﬁlter out these “false positives”? Since we have the coordinates of the local\n",
      "46 | Chapter 4: SciKit: Taking SciPy One Step Further\n",
      "9781449305468_text.\n",
      "pdf   54 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "55:\n",
      "maxima, we can look for properties that will differentiate the sources from the rest.\n",
      " The\n",
      "background is relatively smooth compared to the sources, so we could differentiate them\n",
      "easily by standard deviation from the peaks to their local neighboring pixels.\n",
      "\n",
      "How does scikit-image fare with real-world research problems? Quite well, in fact.\n",
      " In\n",
      "astronomy , the ﬂux per unit area received from stars can be measured in images by quan-\n",
      "tifying intensity levels at their locations—a process called photometry .\n",
      " Photometry has\n",
      "been done for quite some time in multiple progra mming languages, but there is no de\n",
      "facto package for Python yet.\n",
      " The ﬁrst step in photometry is identifying the stars.\n",
      " In the\n",
      "following example, we will use is_local_maximum to identify sources (hopefully stars) in\n",
      "a stellar cluster called NGC 3603 that was observed with the Hubble Space T elescope.\n",
      "\n",
      "Note that one additional package, PyFITS,1is used here.\n",
      " It is a standard astronomical\n",
      "p a c k a g ef o rl o a d i n gb i n a r yd a t as t o r e di nF I T S2format.\n",
      "\n",
      "import numpy as np\n",
      "import pyfits\n",
      "import matplotlib.\n",
      "pyplot as mpl\n",
      "import skimage.\n",
      "morphology as morph\n",
      "import skimage.\n",
      "exposure as skie\n",
      "# Loading astronomy image from an infrared space telescope\n",
      "img = pyfits.\n",
      "getdata('stellar_cluster.\n",
      "fits')[500:1500, 500:1500]\n",
      "# Prep file scikit-image environment and plotting\n",
      "limg = np.\n",
      "arcsinh(img)\n",
      "limg = limg / limg.\n",
      "max()\n",
      "low = np.\n",
      "percentile(limg, 0.\n",
      "25)\n",
      "high = np.\n",
      "percentile(limg, 99.\n",
      "5)\n",
      "opt_img = skie.\n",
      "exposure.\n",
      "rescale_intensity(limg, in_range=(low, high))\n",
      "# Calculating local maxima and filtering out noise\n",
      "lm = morph.\n",
      "is_local_maximum(limg)\n",
      "x1, y1 = np.\n",
      "where(lm.\n",
      "T == True)\n",
      "v = limg[(y1, x1)]\n",
      "lim = 0.\n",
      "5\n",
      "x2, y2 = x1[v > lim], y1[v > lim]\n",
      "# Creating figure to show local maximum detection\n",
      "# rate success\n",
      "fig = mpl.\n",
      "figure(figsize=(8,4))\n",
      "fig.\n",
      "subplots_adjust(hspace=0.\n",
      "05, wspace=0.\n",
      "05)\n",
      "ax1 = fig.\n",
      "add_subplot(121)\n",
      "ax1.\n",
      "imshow(opt_img)\n",
      "ax1.\n",
      "set_xlim(0, img.\n",
      "shape[1])\n",
      "ax1.\n",
      "set_ylim(0, img.\n",
      "shape[0])\n",
      "ax1.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax1.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "1http://www.\n",
      "stsci.\n",
      "edu/institute/software_hardware/pyﬁts\n",
      "2http://heasarc.\n",
      "nasa.\n",
      "gov/docs/heasarc/ﬁts.\n",
      "html\n",
      "4.\n",
      "1 Scikit-Image | 47\n",
      "9781449305468_text.\n",
      "pdf   55 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "56:\n",
      "Figure 4-3.\n",
      " Stars (orange circles) in a Hubble Space T elescope image of a stellar cluster, identiﬁed using\n",
      "theis_local_maximum function.\n",
      "\n",
      "ax2 = fig.\n",
      "add_subplot(122)\n",
      "ax2.\n",
      "imshow(opt_img)\n",
      "ax2.\n",
      "scatter(x2, y2, s=80, facecolor='none', edgecolor='#FF7400')\n",
      "ax2.\n",
      "set_xlim(0, img.\n",
      "shape[1])\n",
      "ax2.\n",
      "set_ylim(0, img.\n",
      "shape[0])\n",
      "ax2.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax2.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "fig.\n",
      "savefig('scikit_image_f03.\n",
      "pdf', bbox_inches='tight')\n",
      "The skimage.\n",
      "morphology.\n",
      "is_local_maximum function returns over 30,000 local maxima\n",
      "in the image, and many of the detections are false positives.\n",
      " We apply a simple threshold\n",
      "value to get rid of any maxima peaks that have a pixel value below 0.\n",
      "5 (from the\n",
      "normalized image) to bring that number down to roughly 200.\n",
      " There are much better\n",
      "ways to ﬁlter out non-stellar maxima (e.\n",
      "g.\n",
      ", noise), but we will still stick with the current\n",
      "method for simplicity .\n",
      " In Figure 4-3 we can see that the detections are good overall.\n",
      " Once\n",
      "we know where the stars are, we can apply ﬂux measurement algorithms, but that goes\n",
      "beyond the scope of this chapter.\n",
      "\n",
      "Hopefully , with this brief overview of what is available in the scikit-image package, you\n",
      "already have a good idea of how it can be used for your objectives.\n",
      "\n",
      "4.\n",
      "2 Scikit-Learn\n",
      "Possibly the most extensive scikit is scikit-learn.\n",
      " It is an easy-to-use machine lea rning\n",
      "bundle that contains a collection of tools associated with supervised and unsupervised\n",
      "learning.\n",
      " Some of you may be asking, “So what can machine lea rning help me do that\n",
      "I could not do before?” One word: predictions.\n",
      "\n",
      "48 | Chapter 4: SciKit: Taking SciPy One Step Further\n",
      "9781449305468_text.\n",
      "pdf   56 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "57:\n",
      "Let us assume that we are given a problem where there is a good sample of empirical\n",
      "data at hand: can predictions be made about it? T o ﬁgure this out, we would try to\n",
      "create an analytical model to describe the data, though that does not a lways work due\n",
      "to complex dependencies.\n",
      " But what if you could feed that data to a machine, teach\n",
      "the machine what is good and bad about the data, and then let it provide its own\n",
      "predictions? That is what machine lea rning is.\n",
      " If used right, it can be very powerful.\n",
      "\n",
      "Not only is the scikit-learn package impressive, but its documentation is generous and\n",
      "well organized3.\n",
      " Rather than reinventing the wheel to show what scikit-learn is, I’m\n",
      "going to take several examples that we did in prior sections and see if scikit-learn could\n",
      "provide better and more elegant solutions.\n",
      " This method of implementing scikit-learn\n",
      "is aimed to inspire you as to how the package could be applied to your own research.\n",
      "\n",
      "4.\n",
      "2.\n",
      "1 Linear Regression\n",
      "In Chapter 3 we ﬁtted a line to a dataset, which is a linear regression problem.\n",
      " If we are\n",
      "dealing with data that has a higher number of dimensions, how do we go about a linear\n",
      "regression solution? Scikit-learn has a large number of tools to do this, such as Lasso\n",
      "and ridge regression.\n",
      " For now we will stick with the ordinary least squares regression\n",
      "function, which solves mathematical problems of the form\n",
      "minw/bardblXβ−y/bardbl (4.\n",
      " 1)\n",
      "where wis the set of coefﬁcients.\n",
      " The number of coefﬁcients depends on the number\n",
      "of dimensions in the data, N(coeff)=MD−1, where M> 1 and is an integer.\n",
      " In the\n",
      "example below we are computing the linear regression of a plane in 3D space, so there\n",
      "are two coefﬁcients to solve for.\n",
      " Here we show how to use LinearRegression to train the\n",
      "model with data, approximate a best ﬁt, give a prediction from the data, and test other\n",
      "data (test) to see how well it ﬁts the model.\n",
      " A visual output of the linear regression is\n",
      "shown in Figure 4-4.\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.\n",
      "pyplot as mpl\n",
      "from mpl_toolkits.\n",
      "mplot3d import Axes3D\n",
      "from sklearn import linear_model\n",
      "from sklearn.\n",
      "datasets.\n",
      "samples_generator import make_regression\n",
      "# Generating synthetic data for training and testing\n",
      "X, y = make_regression(n_samples=100, n_features=2, n_informative=1,\\\n",
      "random_state=0, noise=50)\n",
      "# X and y are values for 3D space.\n",
      " We first need to train\n",
      "# the machine, so we split X and y into X_train, X_test,\n",
      "# y_train, and y_test.\n",
      " The *_train data will be given to the\n",
      "# model to train it.\n",
      "\n",
      "X_train, X_test = X[:80], X[-20:]\n",
      "y_train, y_test = y[:80], y[-20:]\n",
      "3http://scikit-learn.\n",
      "org/\n",
      "4.\n",
      "2 Scikit-Learn | 49\n",
      "9781449305468_text.\n",
      "pdf   57 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "58:\n",
      "Figure 4-4.\n",
      " A scikit-learn linear regression in 3D space.\n",
      "\n",
      "# Creating instance of model\n",
      "regr = linear_model.\n",
      "LinearRegression()\n",
      "# Training the model\n",
      "regr.\n",
      "fit(X_train, y_train)\n",
      "# Printing the coefficients\n",
      "print(regr.\n",
      "coef_)\n",
      "# [-10.\n",
      "25691752 90.\n",
      "5463984 ]\n",
      "# Predicting y-value based on training\n",
      "X1 = np.\n",
      "array([1.\n",
      "2, 4])\n",
      "print(regr.\n",
      "predict(X1))\n",
      "# 350.\n",
      "860363861\n",
      "# With the *_test data we can see how the result matches\n",
      "# the data the model was trained with.\n",
      "\n",
      "# It should be a good match as the *_train and *_test\n",
      "# data come from the same sample.\n",
      " Output: 1 is perfect\n",
      "# prediction and anything lower is worse.\n",
      "\n",
      "print(regr.\n",
      "score(X_test, y_test))\n",
      "# 0.\n",
      "949827492261\n",
      "fig = mpl.\n",
      "figure(figsize=(8, 5))\n",
      "ax = fig.\n",
      "add_subplot(111, projection='3d')\n",
      "# ax = Axes3D(fig)\n",
      "# Data\n",
      "ax.\n",
      "scatter(X_train[:,0], X_train[:,1], y_train, facecolor='#00CC00')\n",
      "ax.\n",
      "scatter(X_test[:,0], X_test[:,1], y_test, facecolor='#FF7800')\n",
      "# Function with coefficient variables\n",
      "coef = regr.\n",
      "coef_\n",
      "line = lambda x1, x2: coef[0] * x1 + coef[1] * x2\n",
      "50 | Chapter 4: SciKit: Taking SciPy One Step Further\n",
      "9781449305468_text.\n",
      "pdf   58 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "59:\n",
      "grid_x1, grid_x2 = np.\n",
      "mgrid[-2:2:10j, -2:2:10j]\n",
      "ax.\n",
      "plot_surface(grid_x1, grid_x2, line(grid_x1, grid_x2),\n",
      "alpha=0.\n",
      "1, color='k')\n",
      "ax.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "ax.\n",
      "zaxis.\n",
      "set_visible(False)\n",
      "fig.\n",
      "savefig('scikit_learn_regression.\n",
      "pdf', bbox='tight')\n",
      "This LinearRegression function can work with much higher dimensions, so dealing\n",
      "with a larger number of inputs in a model is straightforward.\n",
      " It is advisable to look\n",
      "at the other linear regression models4as well, as they may be more appropriate for\n",
      "your data.\n",
      "\n",
      "4.\n",
      "2.\n",
      "2 Clustering\n",
      "SciPy has two packages for cluster analysis with vector quantization ( kmeans ) and hier-\n",
      "archy .\n",
      " The kmeans method was the easier of the two for implementing and segmenting\n",
      "data into several components based on their spatial characteristics.\n",
      " Scikit-learn pro-\n",
      "vides a set of tools5to do more cluster analysis that goes beyond what SciPy has.\n",
      " For\n",
      "a suitable comparison to the kmeans function in SciPy , the DBSCAN algorithm is used in\n",
      "the following example.\n",
      " DBSCAN works by ﬁnding core points that have many data points\n",
      "within a given radius.\n",
      " Once the core is deﬁned, the process is iteratively computed until\n",
      "there are no more core points deﬁnable within the maximum radius? This algorithm\n",
      "does exceptionally well compared to kmeans where there is noise present in the data.\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.\n",
      "pyplot as mpl\n",
      "from scipy.\n",
      "spatial import distance\n",
      "from sklearn.\n",
      "cluster import DBSCAN\n",
      "# Creating data\n",
      "c1 = np.\n",
      "random.\n",
      "randn(100, 2) + 5\n",
      "c2 = np.\n",
      "random.\n",
      "randn(50, 2)\n",
      "# Creating a uniformly distributed background\n",
      "u1 = np.\n",
      "random.\n",
      "uniform(low=-10, high=10, size=100)\n",
      "u2 = np.\n",
      "random.\n",
      "uniform(low=-10, high=10, size=100)\n",
      "c3 = np.\n",
      "column_stack([u1, u2])\n",
      "# Pooling all the data into one 150 x 2 array\n",
      "data = np.\n",
      "vstack([c1, c2, c3])\n",
      "# Calculating the cluster with DBSCAN function.\n",
      "\n",
      "# db.\n",
      "labels_ is an array with identifiers to the\n",
      "# different clusters in the data.\n",
      "\n",
      "db = DBSCAN().\n",
      "fit(data, eps=0.\n",
      "95, min_samples=10)\n",
      "labels = db.\n",
      "labels_\n",
      "4http://www.\n",
      "scikit-learn.\n",
      "org/stable/modules/linear_model.\n",
      "html\n",
      "5http://www.\n",
      "scikit-learn.\n",
      "org/stable/modules/clustering.\n",
      "html\n",
      "4.\n",
      "2 Scikit-Learn | 51\n",
      "9781449305468_text.\n",
      "pdf   59 10/31/12   2:35 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "60:\n",
      "Figure 4-5.\n",
      " An example of how the DBSCAN algorithm excels over the vector quantization package\n",
      "in SciPy.\n",
      " The uniformly distributed points are not included as cluster members.\n",
      "\n",
      "# Retrieving coordinates for points in each\n",
      "# identified core.\n",
      " There are two clusters\n",
      "# denoted as 0 and 1 and the noise is denoted\n",
      "# as -1.\n",
      " Here we split the data based on which\n",
      "# component they belong to.\n",
      "\n",
      "dbc1 = data[labels == 0]\n",
      "dbc2 = data[labels == 1]\n",
      "noise = data[labels == -1]\n",
      "# Setting up plot details\n",
      "x1, x2 = -12, 12\n",
      "y1, y2 = -12, 12\n",
      "fig = mpl.\n",
      "figure()\n",
      "fig.\n",
      "subplots_adjust(hspace=0.\n",
      "1, wspace=0.\n",
      "1)\n",
      "ax1 = fig.\n",
      "add_subplot(121, aspect='equal')\n",
      "ax1.\n",
      "scatter(c1[:,0], c1[:,1], lw=0.\n",
      "5, color='#00CC00')\n",
      "ax1.\n",
      "scatter(c2[:,0], c2[:,1], lw=0.\n",
      "5, color='#028E9B')\n",
      "ax1.\n",
      "scatter(c3[:,0], c3[:,1], lw=0.\n",
      "5, color='#FF7800')\n",
      "ax1.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax1.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "ax1.\n",
      "set_xlim(x1, x2)\n",
      "ax1.\n",
      "set_ylim(y1, y2)\n",
      "ax1.\n",
      "text(-11, 10, 'Original')\n",
      "ax2 = fig.\n",
      "add_subplot(122, aspect='equal')\n",
      "ax2.\n",
      "scatter(dbc1[:,0], dbc1[:,1], lw=0.\n",
      "5, color='#00CC00')\n",
      "ax2.\n",
      "scatter(dbc2[:,0], dbc2[:,1], lw=0.\n",
      "5, color='#028E9B')\n",
      "ax2.\n",
      "scatter(noise[:,0], noise[:,1], lw=0.\n",
      "5, color='#FF7800')\n",
      "ax2.\n",
      "xaxis.\n",
      "set_visible(False)\n",
      "ax2.\n",
      "yaxis.\n",
      "set_visible(False)\n",
      "ax2.\n",
      "set_xlim(x1, x2)\n",
      "ax2.\n",
      "set_ylim(y1, y2)\n",
      "ax2.\n",
      "text(-11, 10, 'DBSCAN identified')\n",
      "fig.\n",
      "savefig('scikit_learn_clusters.\n",
      "pdf', bbox_inches='tight')\n",
      "52 | Chapter 4: SciKit: Taking SciPy One Step Further\n",
      "9781449305468_text.\n",
      "pdf   60 10/31/12   2:36 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "61:\n",
      "Nearly all the data points originally deﬁned to be part of the clusters are retained,\n",
      "and the noisy background data points are excluded (see Figure 4-5).\n",
      " This highlights\n",
      "the advantage of DBSCAN over kmeans when data that should not be part of a cluster is\n",
      "present in a sample.\n",
      " This obviously is dependent on the spatial characteristics of the\n",
      "given distributions.\n",
      "\n",
      "4.\n",
      "2 Scikit-Learn | 53\n",
      "9781449305468_text.\n",
      "pdf   61 10/31/12   2:36 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "62:\n",
      "9781449305468_text.\n",
      "pdf   62 10/31/12   2:36 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "63:\n",
      "CHAPTER 5\n",
      "Conclusion\n",
      "5.\n",
      "1 Summary\n",
      "This book is meant to help you as the reader to become fa miliar with SciPy and\n",
      "NumPy and to walk away with tools that you can use for your own research.\n",
      " The online\n",
      "documentation for SciPy and NumPy is comprehensive, and it takes time to sort out\n",
      "what you want from the packages.\n",
      " We all want to learn new tools and use them with\n",
      "as little time and effort possible.\n",
      " Hopefully , this book was able to do that for you.\n",
      "\n",
      "W e have covered how to utilize NumPy arrays for array indexing, math operat ions, and\n",
      "loading and saving data.\n",
      " With SciPy , we went over tools that are important for scientiﬁc\n",
      "research, such as optimization, interpolation, integration, clustering, statistics, and\n",
      "more.\n",
      " The bulk of the material we discussed was on SciPy since there are so many\n",
      "modules in it.\n",
      "\n",
      "As a bonus, we learned about two powerful scikit packages.\n",
      " Scikit-image is a powerful\n",
      "package that extends beyond the imaging capabilities of SciPy .\n",
      " With scikit-learn, we\n",
      "demonstrated how to employ machine lea rning to solve pr oblems that would have been\n",
      "otherwise tough to solve.\n",
      "\n",
      "5.\n",
      "2 What’s Next?\n",
      "Y ou are now familiar with SciPy , NumPy , and two scikit packages.\n",
      " The funct ions and\n",
      "tools we covered should allow you to comfortably approach your research investigations\n",
      "with more conﬁdence.\n",
      " Moreover, using these resources, you probably see new ways of\n",
      "solving problems that you were not aware of before.\n",
      " If you’re looking for more (e.\n",
      "g.\n",
      ",\n",
      "indeﬁnite integrals), then you should look for other packages.\n",
      " A good o nline resource\n",
      "is the PyPI website,1where thousands of packages are registered.\n",
      " Y ou can simply browse\n",
      "through to ﬁnd what you’re looking for.\n",
      "\n",
      "1http://pypi.\n",
      "python.\n",
      "org/pypi\n",
      "55\n",
      "9781449305468_text.\n",
      "pdf   63 10/31/12   2:36 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "64:\n",
      "Also, joining Python mailing lists associated with your ﬁeld of research is a good idea.\n",
      "\n",
      "Y ou will see many discussions among other Python users and may ﬁnd what you need.\n",
      "\n",
      "Or just ask a question yourself on these lists.\n",
      " Another good information repository is\n",
      "stackoverﬂow.\n",
      "com , which is a central hub where programmers can ask questions, ﬁnd\n",
      "answers, and provide solutions to programming-related problems.\n",
      "\n",
      "56 | Chapter 5: Conclusion\n",
      "9781449305468_text.\n",
      "pdf   64 10/31/12   2:36 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "65:\n",
      "About the Author\n",
      "Eli Bressert was born in Tucson, Arizona.\n",
      " He worked as a science imager for NASA ’ s\n",
      "Chandra X-ray Space T elescope, opt imizing sc ience images that are frequently seen\n",
      "on book covers, newspapers, television, and other media.\n",
      " Afterward, Eli obtained his\n",
      "PhD in astrophysics at the University of Exeter and is currently a Bolton Fellow at\n",
      "CSIRO Astronomy and Space Science in Sydney , Australia.\n",
      " For the last six years, Eli\n",
      "has been programming in Python and giving Python lectures at Harvard Unive rsity ,\n",
      "the European Space Astronomy Centre, and the European Southern Observatory .\n",
      " He\n",
      "is one of the founding developers of two well-known astrophysics Python packages:\n",
      "ATpy and APLpy .\n",
      "\n",
      "57\n",
      "9781449305468_text.\n",
      "pdf   65 10/31/12   2:36 PMwww.\n",
      "it-ebooks.\n",
      "info\n",
      "\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# read the text from pdf file with pypdf2\n",
    "pdfFileObj = open('/Users/matansharon/python/Data_science/papers/SciPy and NumPy pdf - EBook Free Download ( PDFDrive ).pdf','rb')\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "print(len(pdfReader.pages))\n",
    "#devide the text to sentences\n",
    "text = \"\"\n",
    "for i in range(len(pdfReader.pages)):\n",
    "    page = f\"{i}:\\n\"+pdfReader.pages[i].extract_text()+\"\\n\\n\\n\"\n",
    "    #devide the text to sentences\n",
    "    for i in range(len(page.split(\".\"))):\n",
    "        text += page.split(\".\")[i] + \".\\n\"\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
